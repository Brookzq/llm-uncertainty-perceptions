{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b34a8f-d97e-4fd3-98dc-4c50a6c33547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from metrics import assert_valid_prob, assert_same_exprs, compute_interquartile_range\n",
    "from utils_io import read_json\n",
    "from default_vars import UNCERTAINTY_EXPRESSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a2e93-a4f8-43c2-8272-7f0c85a56e60",
   "metadata": {},
   "source": [
    "In this notebook, we will compute the two sets of metrics: \n",
    "- _mode-matching_ metrics, which include the `proportional agreement` and `mean absolute error`.\n",
    "- _distribution matching_ metrics: which include the `wasserstein` distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052390c-cbb9-4fc2-8810-933a44136304",
   "metadata": {},
   "source": [
    "## 1. Interquartile Range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74cd6f2-c8ef-4b12-9385-9c6eb3be060a",
   "metadata": {},
   "source": [
    "### 1.1. Non-verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5125b873-9065-4a55-9203-3786f70696cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncertainty_expression</th>\n",
       "      <th>iqr</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost certain</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>highly likely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very likely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>probable</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somewhat likely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uncertain</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>somewhat unlikely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unlikely</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>not likely</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>very unlikely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>highly unlikely</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uncertainty_expression   iqr    q1    q3\n",
       "0          almost certain   5.0  90.0  95.0\n",
       "1           highly likely  10.0  85.0  95.0\n",
       "2             very likely  15.0  80.0  95.0\n",
       "3                probable  15.0  65.0  80.0\n",
       "4         somewhat likely  15.0  60.0  75.0\n",
       "5                possible  20.0  55.0  75.0\n",
       "6               uncertain  30.0  20.0  50.0\n",
       "7       somewhat unlikely  15.0  25.0  40.0\n",
       "8                unlikely  20.0  10.0  30.0\n",
       "9              not likely  20.0  10.0  30.0\n",
       "10               doubtful  15.0  15.0  30.0\n",
       "11          very unlikely  10.0   5.0  15.0\n",
       "12        highly unlikely   5.0   5.0  10.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_ref_nv = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "# Check that normalized histograms sum to approx 1\n",
    "assert_valid_prob(human_ref_nv)\n",
    "compute_interquartile_range(human_ref_nv, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175d32c4-1b67-4075-95f8-a7075f527d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iqr    15.000000\n",
       "q1     40.384615\n",
       "q3     55.384615\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_interquartile_range(human_ref_nv, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS).drop(\"uncertainty_expression\",axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b6d7c-7b3a-4e7c-8e38-991a2851bfb1",
   "metadata": {},
   "source": [
    "### Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20087215-a356-4325-83f9-82866b3ed178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__meta-llama__Llama-3-70b-chat-hf_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_non_verifiable_results_iqr_greedy = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/greedy/all/non_verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_interquartile_range(model_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        # dist[\"setting\"] = \"non-verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _non_verifiable_results_iqr_greedy.append(dist)\n",
    "\n",
    "    human_df = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "    dist = compute_interquartile_range(human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "    dist[\"n_shots\"] = n_shots\n",
    "    # dist[\"setting\"] = \"non-verifiable\"\n",
    "    dist[\"model\"] = \"humans-filtered\"\n",
    "    _non_verifiable_results_iqr_greedy.append(dist)\n",
    "    \n",
    "_non_verifiable_results_iqr_greedy = pd.concat(_non_verifiable_results_iqr_greedy, axis=0).reset_index(drop=True)\n",
    "_non_verifiable_results_iqr_greedy.loc[\n",
    "    (_non_verifiable_results_iqr_greedy[\"q1\"] == -1)\n",
    "    & (_non_verifiable_results_iqr_greedy[\"q3\"] == -1), \"iqr\"\n",
    "] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1a1a3-9b05-4ddf-816c-4520e9ee3f92",
   "metadata": {},
   "source": [
    "### 1.2. Probabilistic decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a30bf2-4edf-420f-951d-f86e3a9bc316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_non_verifiable_results_iqr_prob = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/probabilistic/all/non_verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_interquartile_range(model_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        # dist[\"setting\"] = \"non-verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _non_verifiable_results_iqr_prob.append(dist)\n",
    "\n",
    "    human_df = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "    dist = compute_interquartile_range(human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "    dist[\"n_shots\"] = n_shots\n",
    "    # dist[\"setting\"] = \"non-verifiable\"\n",
    "    dist[\"model\"] = \"humans-filtered\"\n",
    "    _non_verifiable_results_iqr_prob.append(dist)\n",
    "    \n",
    "_non_verifiable_results_iqr_prob = pd.concat(_non_verifiable_results_iqr_prob, axis=0).reset_index(drop=True)\n",
    "_non_verifiable_results_iqr_prob.loc[\n",
    "    (_non_verifiable_results_iqr_prob[\"q1\"] == -1)\n",
    "    & (_non_verifiable_results_iqr_prob[\"q3\"] == -1), \"iqr\"\n",
    "] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5fd552-43e7-4891-9870-806ddcc7293c",
   "metadata": {},
   "source": [
    "### Non-verifiable Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293ff780-1b5f-4c0d-98a6-cda5e20c824b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iqr-greedy</th>\n",
       "      <th>iqr-prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_shots</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">0</th>\n",
       "      <th>full__allenai__OLMo-7B-Instruct</th>\n",
       "      <td>36.153846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__google__gemma-1.1-2b-it</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>11.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__lmsys__vicuna-13b-v1.5</th>\n",
       "      <td>24.230769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mistralai__Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>7.692308</td>\n",
       "      <td>11.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>8.076923</td>\n",
       "      <td>11.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo-2024-04-09</th>\n",
       "      <td>1.153846</td>\n",
       "      <td>2.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-05-13</th>\n",
       "      <td>3.846154</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans-filtered</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x22B-Instruct-v0.1</th>\n",
       "      <td>5.769231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>4.615385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">2</th>\n",
       "      <th>full__allenai__OLMo-7B-Instruct</th>\n",
       "      <td>36.538462</td>\n",
       "      <td>39.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__google__gemma-1.1-2b-it</th>\n",
       "      <td>23.076923</td>\n",
       "      <td>19.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__lmsys__vicuna-13b-v1.5</th>\n",
       "      <td>18.076923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>1.923077</td>\n",
       "      <td>3.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>15.384615</td>\n",
       "      <td>21.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mistralai__Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>13.076923</td>\n",
       "      <td>13.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>4.615385</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo-2024-04-09</th>\n",
       "      <td>1.153846</td>\n",
       "      <td>1.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-05-13</th>\n",
       "      <td>3.846154</td>\n",
       "      <td>39.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans-filtered</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__meta-llama__Llama-3-70b-chat-hf</th>\n",
       "      <td>2.307692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x22B-Instruct-v0.1</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>4.230769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          iqr-greedy  \\\n",
       "n_shots model                                                          \n",
       "0       full__allenai__OLMo-7B-Instruct                    36.153846   \n",
       "        full__google__gemma-1.1-2b-it                       0.769231   \n",
       "        full__lmsys__vicuna-13b-v1.5                       24.230769   \n",
       "        full__meta-llama__Meta-Llama-3-70B-Instruct         0.769231   \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct         10.000000   \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2           7.692308   \n",
       "        gpt-3.5-turbo-0125                                  8.076923   \n",
       "        gpt-4-turbo-2024-04-09                              1.153846   \n",
       "        gpt-4o-2024-05-13                                   3.846154   \n",
       "        humans-filtered                                    15.000000   \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1    5.769231   \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1     4.615385   \n",
       "2       full__allenai__OLMo-7B-Instruct                    36.538462   \n",
       "        full__google__gemma-1.1-2b-it                      23.076923   \n",
       "        full__lmsys__vicuna-13b-v1.5                       18.076923   \n",
       "        full__meta-llama__Meta-Llama-3-70B-Instruct         1.923077   \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct         15.384615   \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2          13.076923   \n",
       "        gpt-3.5-turbo-0125                                  4.615385   \n",
       "        gpt-4-turbo-2024-04-09                              1.153846   \n",
       "        gpt-4o-2024-05-13                                   3.846154   \n",
       "        humans-filtered                                    15.000000   \n",
       "        sampling__meta-llama__Llama-3-70b-chat-hf           2.307692   \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1    5.000000   \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1     4.230769   \n",
       "\n",
       "                                                           iqr-prob  \n",
       "n_shots model                                                        \n",
       "0       full__allenai__OLMo-7B-Instruct                         NaN  \n",
       "        full__google__gemma-1.1-2b-it                     11.538462  \n",
       "        full__lmsys__vicuna-13b-v1.5                            NaN  \n",
       "        full__meta-llama__Meta-Llama-3-70B-Instruct        1.538462  \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct        21.923077  \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2         11.153846  \n",
       "        gpt-3.5-turbo-0125                                11.538462  \n",
       "        gpt-4-turbo-2024-04-09                             2.692308  \n",
       "        gpt-4o-2024-05-13                                 39.000000  \n",
       "        humans-filtered                                   15.000000  \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1        NaN  \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1         NaN  \n",
       "2       full__allenai__OLMo-7B-Instruct                   39.230769  \n",
       "        full__google__gemma-1.1-2b-it                     19.615385  \n",
       "        full__lmsys__vicuna-13b-v1.5                            NaN  \n",
       "        full__meta-llama__Meta-Llama-3-70B-Instruct        3.076923  \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct        21.538462  \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2         13.076923  \n",
       "        gpt-3.5-turbo-0125                                 9.000000  \n",
       "        gpt-4-turbo-2024-04-09                             1.153846  \n",
       "        gpt-4o-2024-05-13                                 39.153846  \n",
       "        humans-filtered                                   15.000000  \n",
       "        sampling__meta-llama__Llama-3-70b-chat-hf               NaN  \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1        NaN  \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv_iqr_prob_mean = _non_verifiable_results_iqr_prob[[\"n_shots\", \"model\", \"iqr\"]].groupby([\"n_shots\", \"model\"]).mean()\n",
    "nv_iqr_greedy_mean = _non_verifiable_results_iqr_greedy[[\"n_shots\", \"model\", \"iqr\"]].groupby([\"n_shots\", \"model\"]).mean()\n",
    "nv_iqr = nv_iqr_greedy_mean.join(nv_iqr_prob_mean, lsuffix=\"-greedy\", rsuffix=\"-prob\")\n",
    "nv_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61dd0c07-d862-493d-900a-fef1dcd95d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      " &  & iqr-greedy & iqr-prob \\\\\n",
      "n_shots & model &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{12}{*}{0} & full__allenai__OLMo-7B-Instruct & 36.15 & NaN \\\\\n",
      " & full__google__gemma-1.1-2b-it & 0.77 & 11.54 \\\\\n",
      " & full__lmsys__vicuna-13b-v1.5 & 24.23 & NaN \\\\\n",
      " & full__meta-llama__Meta-Llama-3-70B-Instruct & 0.77 & 1.54 \\\\\n",
      " & full__meta-llama__Meta-Llama-3-8B-Instruct & 10.00 & 21.92 \\\\\n",
      " & full__mistralai__Mistral-7B-Instruct-v0.2 & 7.69 & 11.15 \\\\\n",
      " & gpt-3.5-turbo-0125 & 8.08 & 11.54 \\\\\n",
      " & gpt-4-turbo-2024-04-09 & 1.15 & 2.69 \\\\\n",
      " & gpt-4o-2024-05-13 & 3.85 & 39.00 \\\\\n",
      " & humans-filtered & 15.00 & 15.00 \\\\\n",
      " & sampling__mistralai__Mixtral-8x22B-Instruct-v0.1 & 5.77 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x7B-Instruct-v0.1 & 4.62 & NaN \\\\\n",
      "\\cline{1-4}\n",
      "\\multirow[t]{13}{*}{2} & full__allenai__OLMo-7B-Instruct & 36.54 & 39.23 \\\\\n",
      " & full__google__gemma-1.1-2b-it & 23.08 & 19.62 \\\\\n",
      " & full__lmsys__vicuna-13b-v1.5 & 18.08 & NaN \\\\\n",
      " & full__meta-llama__Meta-Llama-3-70B-Instruct & 1.92 & 3.08 \\\\\n",
      " & full__meta-llama__Meta-Llama-3-8B-Instruct & 15.38 & 21.54 \\\\\n",
      " & full__mistralai__Mistral-7B-Instruct-v0.2 & 13.08 & 13.08 \\\\\n",
      " & gpt-3.5-turbo-0125 & 4.62 & 9.00 \\\\\n",
      " & gpt-4-turbo-2024-04-09 & 1.15 & 1.15 \\\\\n",
      " & gpt-4o-2024-05-13 & 3.85 & 39.15 \\\\\n",
      " & humans-filtered & 15.00 & 15.00 \\\\\n",
      " & sampling__meta-llama__Llama-3-70b-chat-hf & 2.31 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x22B-Instruct-v0.1 & 5.00 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x7B-Instruct-v0.1 & 4.23 & NaN \\\\\n",
      "\\cline{1-4}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nv_iqr.to_latex(\n",
    "    float_format=\"%.2f\", index=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f990258f-f721-4e6c-9c8d-fcc470e9be53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iqr_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_shots</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.604396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          iqr_diff\n",
       "n_shots           \n",
       "0        10.602564\n",
       "2         6.604396"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv_iqr[\"iqr_diff\"] = (nv_iqr[\"iqr-prob\"] - nv_iqr[\"iqr-greedy\"])\n",
    "nv_iqr_ = nv_iqr.reset_index()\n",
    "nv_iqr_[~nv_iqr_[\"model\"].isin([\"humans-filtered\", \"full__mistralai__Mistral-7B-Instruct-v0.2\"])].dropna().reset_index()[[\"n_shots\", \"iqr_diff\"]].groupby([\"n_shots\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec6b8a15-c5f0-4cd8-a855-a063128bbe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_shots</th>\n",
       "      <th>model</th>\n",
       "      <th>iqr-greedy</th>\n",
       "      <th>iqr-prob</th>\n",
       "      <th>iqr_diff</th>\n",
       "      <th>iqr-greedy_diff</th>\n",
       "      <th>iqr-prob_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>full__allenai__OLMo-7B-Instruct</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>39.230769</td>\n",
       "      <td>2.692308</td>\n",
       "      <td>21.538462</td>\n",
       "      <td>24.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>full__google__gemma-1.1-2b-it</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>19.615385</td>\n",
       "      <td>-3.461538</td>\n",
       "      <td>8.076923</td>\n",
       "      <td>4.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>-13.076923</td>\n",
       "      <td>-11.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>21.538462</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>6.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>-10.384615</td>\n",
       "      <td>-6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>gpt-4-turbo-2024-04-09</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.846154</td>\n",
       "      <td>-13.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>39.153846</td>\n",
       "      <td>35.307692</td>\n",
       "      <td>-11.153846</td>\n",
       "      <td>24.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>humans-filtered</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>sampling__mistralai__Mixtral-8x22B-Instruct-v0.1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>sampling__mistralai__Mixtral-8x7B-Instruct-v0.1</td>\n",
       "      <td>4.230769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.769231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_shots                                             model  iqr-greedy  \\\n",
       "12        2                   full__allenai__OLMo-7B-Instruct   36.538462   \n",
       "13        2                     full__google__gemma-1.1-2b-it   23.076923   \n",
       "15        2       full__meta-llama__Meta-Llama-3-70B-Instruct    1.923077   \n",
       "16        2        full__meta-llama__Meta-Llama-3-8B-Instruct   15.384615   \n",
       "18        2                                gpt-3.5-turbo-0125    4.615385   \n",
       "19        2                            gpt-4-turbo-2024-04-09    1.153846   \n",
       "20        2                                 gpt-4o-2024-05-13    3.846154   \n",
       "21        2                                   humans-filtered   15.000000   \n",
       "23        2  sampling__mistralai__Mixtral-8x22B-Instruct-v0.1    5.000000   \n",
       "24        2   sampling__mistralai__Mixtral-8x7B-Instruct-v0.1    4.230769   \n",
       "\n",
       "     iqr-prob   iqr_diff  iqr-greedy_diff  iqr-prob_diff  \n",
       "12  39.230769   2.692308        21.538462      24.230769  \n",
       "13  19.615385  -3.461538         8.076923       4.615385  \n",
       "15   3.076923   1.153846       -13.076923     -11.923077  \n",
       "16  21.538462   6.153846         0.384615       6.538462  \n",
       "18   9.000000   4.384615       -10.384615      -6.000000  \n",
       "19   1.153846   0.000000       -13.846154     -13.846154  \n",
       "20  39.153846  35.307692       -11.153846      24.153846  \n",
       "21  15.000000   0.000000         0.000000       0.000000  \n",
       "23        NaN        NaN       -10.000000            NaN  \n",
       "24        NaN        NaN       -10.769231            NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv_iqr_ = nv_iqr.reset_index().copy()\n",
    "\n",
    "\n",
    "nv_iqr_[\"iqr-greedy_diff\"] = (nv_iqr_[\"iqr-greedy\"]-15)\n",
    "nv_iqr_[\"iqr-prob_diff\"] = (nv_iqr_[\"iqr-prob\"]-15)\n",
    "\n",
    "nv_iqr_ = nv_iqr_[nv_iqr_[\"n_shots\"] == 2]\n",
    "nv_iqr_[~nv_iqr_[\"model\"].isin([\n",
    "    \"full__mistralai__Mistral-7B-Instruct-v0.2\",\n",
    "    \"sampling__meta-llama__Llama-3-70b-chat-hf\",\n",
    "    \"full__lmsys__vicuna-13b-v1.5\",\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d62d3-931e-499b-913e-9a5326c69a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_non_verifiable_results_iqr_greedy[_non_verifiable_results_iqr_greedy[\"model\"] == \"full__meta-llama__Meta-Llama-3-70B-Instruct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784f693-5754-441e-ba8d-e05df5d8bc3e",
   "metadata": {},
   "source": [
    "## 2. Verifiable (main experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6524d4-e314-4d23-a9cb-4e93f536407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_ref_v = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "# Check that normalized histograms sum to approx 1\n",
    "assert_valid_prob(human_ref_v)\n",
    "\n",
    "# Check that both files concern the same uncertainty expressions, ordered in the same way\n",
    "assert_same_exprs(human_ref_v, human_ref_v)\n",
    "compute_interquartile_range(human_ref_v, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\\\n",
    "    .drop(\"uncertainty_expression\",axis=1)\\\n",
    "    .mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad210f-ef4d-4108-8273-76b909e6fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_interquartile_range(human_ref_v, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbfc6c9-7284-4c27-8460-0cf7c7c2ae52",
   "metadata": {},
   "source": [
    "### 2.1. Greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b652f9a-febb-40fc-9735-862b4ea0f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_verifiable_results_iqr_greedy = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/greedy/all/verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_interquartile_range(model_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        # dist[\"setting\"] = \"verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _verifiable_results_iqr_greedy.append(dist)\n",
    "\n",
    "    human_df = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "    dist = compute_interquartile_range(human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "    dist[\"n_shots\"] = n_shots\n",
    "    # dist[\"setting\"] = \"verifiable\"\n",
    "    dist[\"model\"] = \"humans-filtered\"\n",
    "    _verifiable_results_iqr_greedy.append(dist)\n",
    "    \n",
    "_verifiable_results_iqr_greedy = pd.concat(_verifiable_results_iqr_greedy, axis=0).reset_index(drop=True)\n",
    "_verifiable_results_iqr_greedy.loc[\n",
    "    (_verifiable_results_iqr_greedy[\"q1\"] == -1)\n",
    "    & (_verifiable_results_iqr_greedy[\"q3\"] == -1), \"iqr\"\n",
    "] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e4f67-6aa3-41bc-9a68-8db27dc72c13",
   "metadata": {},
   "source": [
    "### 2.2. Probabilistic decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c55fa-c461-4d1b-8d51-e7eb7a61c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_verifiable_results_iqr_prob = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/probabilistic/all/verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_interquartile_range(model_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        # dist[\"setting\"] = \"non-verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _verifiable_results_iqr_prob.append(dist)\n",
    "\n",
    "    human_df = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "    dist = compute_interquartile_range(human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "    dist[\"n_shots\"] = n_shots\n",
    "    # dist[\"setting\"] = \"non-verifiable\"\n",
    "    dist[\"model\"] = \"humans-filtered\"\n",
    "    _verifiable_results_iqr_prob.append(dist)\n",
    "    \n",
    "_verifiable_results_iqr_prob = pd.concat(_verifiable_results_iqr_prob, axis=0).reset_index(drop=True)\n",
    "# If all predictions were -1\n",
    "_verifiable_results_iqr_prob.loc[\n",
    "    (_verifiable_results_iqr_prob[\"q1\"] == -1)\n",
    "    & (_verifiable_results_iqr_prob[\"q3\"] == -1), \"iqr\"\n",
    "] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba7cff-3680-4ac6-adaf-45fac992525d",
   "metadata": {},
   "source": [
    "### 2.3. Final IQR results (verifiable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10ab42-45c6-4cd5-a319-ac86ef59994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_iqr_prob_mean = _verifiable_results_iqr_prob[[\"n_shots\", \"model\", \"iqr\"]].groupby([\"n_shots\", \"model\"]).mean()\n",
    "v_iqr_greedy_mean = _verifiable_results_iqr_greedy[[\"n_shots\", \"model\", \"iqr\"]].groupby([\"n_shots\", \"model\"]).mean()\n",
    "v_iqr = v_iqr_greedy_mean.join(v_iqr_prob_mean, lsuffix=\"-greedy\", rsuffix=\"-prob\")\n",
    "v_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e5786-c0ef-45e4-9141-499e2870511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v_iqr.to_latex(float_format=\"%.2f\", index=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f86f99-814e-479c-b556-06bca3cdc81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why do we get 0s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000ba0c-4e71-4be7-8733-f143596e8f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b257d7a-9c79-4521-8151-e32027988977",
   "metadata": {},
   "source": [
    "### 1.2. Verifiable (generalization experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabb1e5-8e51-41cb-b18a-f87d1cd40467",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_ref_v = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "# Check that normalized histograms sum to approx 1\n",
    "assert_valid_prob(human_ref_v)\n",
    "\n",
    "# Check that both files concern the same uncertainty expressions, ordered in the same way\n",
    "assert_same_exprs(human_ref_v, human_ref_v)\n",
    "compute_interquartile_range(human_ref_v, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\\\n",
    "    .drop(\"uncertainty_expression\",axis=1)\\\n",
    "    .mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
