{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b34a8f-d97e-4fd3-98dc-4c50a6c33547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from metrics import assert_valid_prob, assert_same_exprs, compute_wasserstein_distance, compute_mean_conf_error, compute_proportional_agreement\n",
    "from utils_io import read_json\n",
    "from default_vars import UNCERTAINTY_EXPRESSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a2e93-a4f8-43c2-8272-7f0c85a56e60",
   "metadata": {},
   "source": [
    "In this notebook, we will compute the two sets of metrics: \n",
    "- _mode-matching_ metrics, which include the `proportional agreement` and `mean absolute error`.\n",
    "- _distribution matching_ metrics: which include the `wasserstein` distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052390c-cbb9-4fc2-8810-933a44136304",
   "metadata": {},
   "source": [
    "## 1. Wasserstein Distance\n",
    "\n",
    "Since we already stored the normalized histograms, it is relatively trivial to compute the wasserstein distance across different histograms. The final reported result is the median of the Wasserstein distance for all 14 uncertainty expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5125b873-9065-4a55-9203-3786f70696cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncertainty_expression</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost certain</td>\n",
       "      <td>1.907722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>highly likely</td>\n",
       "      <td>1.351901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very likely</td>\n",
       "      <td>3.441908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>probable</td>\n",
       "      <td>1.316639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somewhat likely</td>\n",
       "      <td>2.234939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>2.324886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uncertain</td>\n",
       "      <td>2.751913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>somewhat unlikely</td>\n",
       "      <td>2.009622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unlikely</td>\n",
       "      <td>2.088812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>not likely</td>\n",
       "      <td>1.778628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>2.749223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>very unlikely</td>\n",
       "      <td>1.939696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>highly unlikely</td>\n",
       "      <td>1.281377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uncertainty_expression  distance\n",
       "0          almost certain  1.907722\n",
       "1           highly likely  1.351901\n",
       "2             very likely  3.441908\n",
       "3                probable  1.316639\n",
       "4         somewhat likely  2.234939\n",
       "5                possible  2.324886\n",
       "6               uncertain  2.751913\n",
       "7       somewhat unlikely  2.009622\n",
       "8                unlikely  2.088812\n",
       "9              not likely  1.778628\n",
       "10               doubtful  2.749223\n",
       "11          very unlikely  1.939696\n",
       "12        highly unlikely  1.281377"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_ref_nv = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "# Check that normalized histograms sum to approx 1\n",
    "assert_valid_prob(human_ref_nv)\n",
    "\n",
    "human_ref_v = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "# Check that normalized histograms sum to approx 1\n",
    "assert_valid_prob(human_ref_v)\n",
    "\n",
    "# Check that both files concern the same uncertainty expressions, ordered in the same way\n",
    "assert_same_exprs(human_ref_v, human_ref_nv)\n",
    "compute_wasserstein_distance(human_ref_nv, human_ref_v, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a2efc6-f959-4f27-abd5-8fd9bfdb544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__meta-llama__Llama-3-70b-chat-hf_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_non_verifiable_results_ws = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/greedy/all/non_verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        human_df = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_wasserstein_distance(model_df, human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        dist[\"setting\"] = \"non-verifiable\"\n",
    "        \n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _non_verifiable_results_ws.append(dist)\n",
    "\n",
    "_non_verifiable_results_ws = pd.concat(_non_verifiable_results_ws, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c06747-5052-44e8-a602-9dccaecc032b",
   "metadata": {},
   "source": [
    "## 2. Proportional Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb769136-c521-4f8a-80fd-f2100df33cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__meta-llama__Llama-3-70b-chat-hf_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_non_verifiable_results_pa = []\n",
    "\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/greedy/all/non_verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        human_df = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_proportional_agreement(model_df, human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        dist[\"setting\"] = \"non-verifiable\"\n",
    "        \n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _non_verifiable_results_pa.append(dist)\n",
    "\n",
    "_non_verifiable_results_pa = pd.concat(_non_verifiable_results_pa, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def9e049-3511-4713-a9fe-9d680c3bccd0",
   "metadata": {},
   "source": [
    "## 3. Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c84512-f529-4ee0-8122-513ce7cce907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__meta-llama__Llama-3-70b-chat-hf_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_non_verifiable_results_mae = []\n",
    "\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/greedy/all/non_verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        human_df = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_mean_conf_error(model_df, human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"distance\"] = dist[\"distance\"].apply(np.abs)\n",
    "        \n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        dist[\"setting\"] = \"non-verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _non_verifiable_results_mae.append(dist)\n",
    "\n",
    "_non_verifiable_results_mae = pd.concat(_non_verifiable_results_mae, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5ecd8-ca5f-4f44-bda6-07e93dbdcbe4",
   "metadata": {},
   "source": [
    "## IQR Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d8344-ebd0-439d-afbe-42db616dd92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6524d4-e314-4d23-a9cb-4e93f536407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iqr(expr_dist):\n",
    "    import numpy as np\n",
    "    \n",
    "    # Histogram data: bin edges and frequencies\n",
    "    bins, frequencies = zip(*expr_dist.items())\n",
    "    bin_edges = get_bin_edges(bins)\n",
    "    \n",
    "    # Calculate the cumulative frequencies\n",
    "    cumulative_frequencies = np.cumsum(frequencies)\n",
    "    \n",
    "    # Determine the positions of the 25th and 75th percentiles\n",
    "    Q1_pos = 0.25\n",
    "    Q3_pos = 0.75\n",
    "    \n",
    "    # Find the bins where Q1 and Q3 lie\n",
    "    Q1_bin = np.searchsorted(cumulative_frequencies, Q1_pos)\n",
    "    Q3_bin = np.searchsorted(cumulative_frequencies, Q3_pos)\n",
    "    \n",
    "    # Interpolate within the bins to find Q1 and Q3\n",
    "    def interpolate(bin_edges, frequencies, cumulative_frequencies, pos, bin_index):\n",
    "        if bin_index == 0:\n",
    "            left_edge = bin_edges[0]\n",
    "        else:\n",
    "            left_edge = bin_edges[bin_index]\n",
    "        \n",
    "        right_edge = bin_edges[bin_index + 1]\n",
    "        left_cum_freq = cumulative_frequencies[bin_index - 1] if bin_index > 0 else 0\n",
    "        bin_freq = frequencies[bin_index]\n",
    "        \n",
    "        proportion = (pos - left_cum_freq) / bin_freq\n",
    "        return left_edge + proportion * (right_edge - left_edge)\n",
    "    \n",
    "    Q1 = interpolate(bin_edges, frequencies, cumulative_frequencies, Q1_pos, Q1_bin)\n",
    "    Q3 = interpolate(bin_edges, frequencies, cumulative_frequencies, Q3_pos, Q3_bin)\n",
    "    \n",
    "    # Compute the IQR\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
    "    return Q1, Q3, IQR\n",
    "\n",
    "\n",
    "def compute_iqr_dist(dists: dict):\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    for expr, expr_dist in dists.items():\n",
    "        results[\"expression\"].append(expr)\n",
    "        out = compute_iqr(expr_dist)\n",
    "        results[\"q1\"].append(out[0])\n",
    "        results[\"q3\"].append(out[1])\n",
    "        results[\"iqr\"].append(out[2])\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad210f-ef4d-4108-8273-76b909e6fcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
