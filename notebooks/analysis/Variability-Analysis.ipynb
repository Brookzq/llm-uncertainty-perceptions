{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b34a8f-d97e-4fd3-98dc-4c50a6c33547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from metrics import assert_valid_prob, assert_same_exprs, compute_interquartile_range\n",
    "from utils_io import read_json\n",
    "from default_vars import UNCERTAINTY_EXPRESSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a2e93-a4f8-43c2-8272-7f0c85a56e60",
   "metadata": {},
   "source": [
    "In this notebook, we will compute the two sets of metrics: \n",
    "- _mode-matching_ metrics, which include the `proportional agreement` and `mean absolute error`.\n",
    "- _distribution matching_ metrics: which include the `wasserstein` distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052390c-cbb9-4fc2-8810-933a44136304",
   "metadata": {},
   "source": [
    "## 1. Interquartile Range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74cd6f2-c8ef-4b12-9385-9c6eb3be060a",
   "metadata": {},
   "source": [
    "### 1.1. Non-verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5125b873-9065-4a55-9203-3786f70696cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncertainty_expression</th>\n",
       "      <th>iqr</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost certain</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>highly likely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very likely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>probable</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somewhat likely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uncertain</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>somewhat unlikely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unlikely</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>not likely</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>very unlikely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>highly unlikely</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uncertainty_expression   iqr    q1    q3\n",
       "0          almost certain   5.0  90.0  95.0\n",
       "1           highly likely  10.0  85.0  95.0\n",
       "2             very likely  15.0  80.0  95.0\n",
       "3                probable  15.0  65.0  80.0\n",
       "4         somewhat likely  15.0  60.0  75.0\n",
       "5                possible  20.0  55.0  75.0\n",
       "6               uncertain  30.0  20.0  50.0\n",
       "7       somewhat unlikely  15.0  25.0  40.0\n",
       "8                unlikely  20.0  10.0  30.0\n",
       "9              not likely  20.0  10.0  30.0\n",
       "10               doubtful  15.0  15.0  30.0\n",
       "11          very unlikely  10.0   5.0  15.0\n",
       "12        highly unlikely   5.0   5.0  10.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_ref_nv = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "# Check that normalized histograms sum to approx 1\n",
    "assert_valid_prob(human_ref_nv)\n",
    "compute_interquartile_range(human_ref_nv, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175d32c4-1b67-4075-95f8-a7075f527d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iqr    15.000000\n",
       "q1     40.384615\n",
       "q3     55.384615\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_interquartile_range(human_ref_nv, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS).drop(\"uncertainty_expression\",axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b6d7c-7b3a-4e7c-8e38-991a2851bfb1",
   "metadata": {},
   "source": [
    "### Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20087215-a356-4325-83f9-82866b3ed178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-0shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__meta-llama__Llama-3-70b-chat-hf_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/non_verifiable/models-2shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_non_verifiable_results_iqr_greedy = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/greedy/all/non_verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_interquartile_range(model_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        # dist[\"setting\"] = \"non-verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _non_verifiable_results_iqr_greedy.append(dist)\n",
    "\n",
    "    human_df = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "    dist = compute_interquartile_range(human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "    dist[\"n_shots\"] = n_shots\n",
    "    # dist[\"setting\"] = \"non-verifiable\"\n",
    "    dist[\"model\"] = \"humans-filtered\"\n",
    "    _non_verifiable_results_iqr_greedy.append(dist)\n",
    "    \n",
    "_non_verifiable_results_iqr_greedy = pd.concat(_non_verifiable_results_iqr_greedy, axis=0).reset_index(drop=True)\n",
    "_non_verifiable_results_iqr_greedy.loc[\n",
    "    (_non_verifiable_results_iqr_greedy[\"q1\"] == -1)\n",
    "    & (_non_verifiable_results_iqr_greedy[\"q3\"] == -1), \"iqr\"\n",
    "] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1a1a3-9b05-4ddf-816c-4520e9ee3f92",
   "metadata": {},
   "source": [
    "### 1.2. Probabilistic decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a30bf2-4edf-420f-951d-f86e3a9bc316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-70B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/probabilistic/all/non_verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_non_verifiable_results_iqr_prob = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/probabilistic/all/non_verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_interquartile_range(model_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        # dist[\"setting\"] = \"non-verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _non_verifiable_results_iqr_prob.append(dist)\n",
    "\n",
    "    human_df = pd.read_csv(\"../../results/greedy/all/non_verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "    dist = compute_interquartile_range(human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "    dist[\"n_shots\"] = n_shots\n",
    "    # dist[\"setting\"] = \"non-verifiable\"\n",
    "    dist[\"model\"] = \"humans-filtered\"\n",
    "    _non_verifiable_results_iqr_prob.append(dist)\n",
    "    \n",
    "_non_verifiable_results_iqr_prob = pd.concat(_non_verifiable_results_iqr_prob, axis=0).reset_index(drop=True)\n",
    "_non_verifiable_results_iqr_prob.loc[\n",
    "    (_non_verifiable_results_iqr_prob[\"q1\"] == -1)\n",
    "    & (_non_verifiable_results_iqr_prob[\"q3\"] == -1), \"iqr\"\n",
    "] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5fd552-43e7-4891-9870-806ddcc7293c",
   "metadata": {},
   "source": [
    "### Non-verifiable Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "293ff780-1b5f-4c0d-98a6-cda5e20c824b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iqr-greedy</th>\n",
       "      <th>iqr-prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_shots</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">0</th>\n",
       "      <th>full__allenai__OLMo-7B-Instruct</th>\n",
       "      <td>36.153846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__google__gemma-1.1-2b-it</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>11.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__lmsys__vicuna-13b-v1.5</th>\n",
       "      <td>24.230769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mistralai__Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>7.692308</td>\n",
       "      <td>11.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>8.076923</td>\n",
       "      <td>11.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo-2024-04-09</th>\n",
       "      <td>1.153846</td>\n",
       "      <td>2.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-05-13</th>\n",
       "      <td>3.846154</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans-filtered</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x22B-Instruct-v0.1</th>\n",
       "      <td>5.769231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>4.615385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">2</th>\n",
       "      <th>full__allenai__OLMo-7B-Instruct</th>\n",
       "      <td>36.538462</td>\n",
       "      <td>39.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__google__gemma-1.1-2b-it</th>\n",
       "      <td>23.076923</td>\n",
       "      <td>19.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__lmsys__vicuna-13b-v1.5</th>\n",
       "      <td>18.076923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>1.923077</td>\n",
       "      <td>3.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>15.384615</td>\n",
       "      <td>21.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mistralai__Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>13.076923</td>\n",
       "      <td>13.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>4.615385</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo-2024-04-09</th>\n",
       "      <td>1.153846</td>\n",
       "      <td>1.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-05-13</th>\n",
       "      <td>3.846154</td>\n",
       "      <td>39.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans-filtered</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__meta-llama__Llama-3-70b-chat-hf</th>\n",
       "      <td>2.307692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x22B-Instruct-v0.1</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>4.230769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          iqr-greedy  \\\n",
       "n_shots model                                                          \n",
       "0       full__allenai__OLMo-7B-Instruct                    36.153846   \n",
       "        full__google__gemma-1.1-2b-it                       0.769231   \n",
       "        full__lmsys__vicuna-13b-v1.5                       24.230769   \n",
       "        full__meta-llama__Meta-Llama-3-70B-Instruct         0.769231   \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct         10.000000   \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2           7.692308   \n",
       "        gpt-3.5-turbo-0125                                  8.076923   \n",
       "        gpt-4-turbo-2024-04-09                              1.153846   \n",
       "        gpt-4o-2024-05-13                                   3.846154   \n",
       "        humans-filtered                                    15.000000   \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1    5.769231   \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1     4.615385   \n",
       "2       full__allenai__OLMo-7B-Instruct                    36.538462   \n",
       "        full__google__gemma-1.1-2b-it                      23.076923   \n",
       "        full__lmsys__vicuna-13b-v1.5                       18.076923   \n",
       "        full__meta-llama__Meta-Llama-3-70B-Instruct         1.923077   \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct         15.384615   \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2          13.076923   \n",
       "        gpt-3.5-turbo-0125                                  4.615385   \n",
       "        gpt-4-turbo-2024-04-09                              1.153846   \n",
       "        gpt-4o-2024-05-13                                   3.846154   \n",
       "        humans-filtered                                    15.000000   \n",
       "        sampling__meta-llama__Llama-3-70b-chat-hf           2.307692   \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1    5.000000   \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1     4.230769   \n",
       "\n",
       "                                                           iqr-prob  \n",
       "n_shots model                                                        \n",
       "0       full__allenai__OLMo-7B-Instruct                         NaN  \n",
       "        full__google__gemma-1.1-2b-it                     11.538462  \n",
       "        full__lmsys__vicuna-13b-v1.5                            NaN  \n",
       "        full__meta-llama__Meta-Llama-3-70B-Instruct        1.538462  \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct        21.923077  \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2         11.153846  \n",
       "        gpt-3.5-turbo-0125                                11.538462  \n",
       "        gpt-4-turbo-2024-04-09                             2.692308  \n",
       "        gpt-4o-2024-05-13                                 39.000000  \n",
       "        humans-filtered                                   15.000000  \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1        NaN  \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1         NaN  \n",
       "2       full__allenai__OLMo-7B-Instruct                   39.230769  \n",
       "        full__google__gemma-1.1-2b-it                     19.615385  \n",
       "        full__lmsys__vicuna-13b-v1.5                            NaN  \n",
       "        full__meta-llama__Meta-Llama-3-70B-Instruct        3.076923  \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct        21.538462  \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2         13.076923  \n",
       "        gpt-3.5-turbo-0125                                 9.000000  \n",
       "        gpt-4-turbo-2024-04-09                             1.153846  \n",
       "        gpt-4o-2024-05-13                                 39.153846  \n",
       "        humans-filtered                                   15.000000  \n",
       "        sampling__meta-llama__Llama-3-70b-chat-hf               NaN  \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1        NaN  \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1         NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv_iqr_prob_mean = _non_verifiable_results_iqr_prob[[\"n_shots\", \"model\", \"iqr\"]].groupby([\"n_shots\", \"model\"]).mean()\n",
    "nv_iqr_greedy_mean = _non_verifiable_results_iqr_greedy[[\"n_shots\", \"model\", \"iqr\"]].groupby([\"n_shots\", \"model\"]).mean()\n",
    "nv_iqr_greedy_mean.join(nv_iqr_prob_mean, lsuffix=\"-greedy\", rsuffix=\"-prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61dd0c07-d862-493d-900a-fef1dcd95d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      " &  & iqr-greedy & iqr-prob \\\\\n",
      "n_shots & model &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{12}{*}{0} & full__allenai__OLMo-7B-Instruct & 36.15 & NaN \\\\\n",
      " & full__google__gemma-1.1-2b-it & 0.77 & 11.54 \\\\\n",
      " & full__lmsys__vicuna-13b-v1.5 & 24.23 & NaN \\\\\n",
      " & full__meta-llama__Meta-Llama-3-70B-Instruct & 0.77 & 1.54 \\\\\n",
      " & full__meta-llama__Meta-Llama-3-8B-Instruct & 10.00 & 21.92 \\\\\n",
      " & full__mistralai__Mistral-7B-Instruct-v0.2 & 7.69 & 11.15 \\\\\n",
      " & gpt-3.5-turbo-0125 & 8.08 & 11.54 \\\\\n",
      " & gpt-4-turbo-2024-04-09 & 1.15 & 2.69 \\\\\n",
      " & gpt-4o-2024-05-13 & 3.85 & 39.00 \\\\\n",
      " & humans-filtered & 15.00 & 15.00 \\\\\n",
      " & sampling__mistralai__Mixtral-8x22B-Instruct-v0.1 & 5.77 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x7B-Instruct-v0.1 & 4.62 & NaN \\\\\n",
      "\\cline{1-4}\n",
      "\\multirow[t]{13}{*}{2} & full__allenai__OLMo-7B-Instruct & 36.54 & 39.23 \\\\\n",
      " & full__google__gemma-1.1-2b-it & 23.08 & 19.62 \\\\\n",
      " & full__lmsys__vicuna-13b-v1.5 & 18.08 & NaN \\\\\n",
      " & full__meta-llama__Meta-Llama-3-70B-Instruct & 1.92 & 3.08 \\\\\n",
      " & full__meta-llama__Meta-Llama-3-8B-Instruct & 15.38 & 21.54 \\\\\n",
      " & full__mistralai__Mistral-7B-Instruct-v0.2 & 13.08 & 13.08 \\\\\n",
      " & gpt-3.5-turbo-0125 & 4.62 & 9.00 \\\\\n",
      " & gpt-4-turbo-2024-04-09 & 1.15 & 1.15 \\\\\n",
      " & gpt-4o-2024-05-13 & 3.85 & 39.15 \\\\\n",
      " & humans-filtered & 15.00 & 15.00 \\\\\n",
      " & sampling__meta-llama__Llama-3-70b-chat-hf & 2.31 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x22B-Instruct-v0.1 & 5.00 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x7B-Instruct-v0.1 & 4.23 & NaN \\\\\n",
      "\\cline{1-4}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nv_iqr_greedy_mean.join(nv_iqr_prob_mean, lsuffix=\"-greedy\", rsuffix=\"-prob\").to_latex(\n",
    "    float_format=\"%.2f\", index=None\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "196d62d3-931e-499b-913e-9a5326c69a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncertainty_expression</th>\n",
       "      <th>iqr</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>highly likely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>very likely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>probable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>somewhat likely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>possible</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>somewhat unlikely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>unlikely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>not likely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>very unlikely</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>highly unlikely</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>highly likely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>very likely</td>\n",
       "      <td>5.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>probable</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>somewhat likely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>possible</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>somewhat unlikely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>unlikely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>not likely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>very unlikely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>highly unlikely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>full__meta-llama__Meta-Llama-3-70B-Instruct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uncertainty_expression   iqr    q1    q3  n_shots  \\\n",
       "39          almost certain   0.0  90.0  90.0        0   \n",
       "40           highly likely   0.0  80.0  80.0        0   \n",
       "41             very likely   0.0  80.0  80.0        0   \n",
       "42                probable   0.0  70.0  70.0        0   \n",
       "43         somewhat likely   0.0  60.0  60.0        0   \n",
       "44                possible   0.0  50.0  50.0        0   \n",
       "45               uncertain   0.0  50.0  50.0        0   \n",
       "46       somewhat unlikely   0.0  30.0  30.0        0   \n",
       "47                unlikely   0.0  30.0  30.0        0   \n",
       "48              not likely   0.0  30.0  30.0        0   \n",
       "49                doubtful   0.0  30.0  30.0        0   \n",
       "50           very unlikely   5.0  15.0  20.0        0   \n",
       "51         highly unlikely   5.0  10.0  15.0        0   \n",
       "195         almost certain   0.0  95.0  95.0        2   \n",
       "196          highly likely   0.0  85.0  85.0        2   \n",
       "197            very likely   5.0  80.0  85.0        2   \n",
       "198               probable  10.0  70.0  80.0        2   \n",
       "199        somewhat likely   0.0  60.0  60.0        2   \n",
       "200               possible   0.0  50.0  50.0        2   \n",
       "201              uncertain   0.0  50.0  50.0        2   \n",
       "202      somewhat unlikely   0.0  30.0  30.0        2   \n",
       "203               unlikely   0.0  20.0  20.0        2   \n",
       "204             not likely  10.0  20.0  30.0        2   \n",
       "205               doubtful   0.0  20.0  20.0        2   \n",
       "206          very unlikely   0.0  10.0  10.0        2   \n",
       "207        highly unlikely   0.0  10.0  10.0        2   \n",
       "\n",
       "                                           model  \n",
       "39   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "40   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "41   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "42   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "43   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "44   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "45   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "46   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "47   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "48   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "49   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "50   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "51   full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "195  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "196  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "197  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "198  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "199  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "200  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "201  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "202  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "203  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "204  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "205  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "206  full__meta-llama__Meta-Llama-3-70B-Instruct  \n",
       "207  full__meta-llama__Meta-Llama-3-70B-Instruct  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_non_verifiable_results_iqr_greedy[_non_verifiable_results_iqr_greedy[\"model\"] == \"full__meta-llama__Meta-Llama-3-70B-Instruct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784f693-5754-441e-ba8d-e05df5d8bc3e",
   "metadata": {},
   "source": [
    "## 2. Verifiable (main experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e6524d4-e314-4d23-a9cb-4e93f536407d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iqr    13.846154\n",
       "q1     41.153846\n",
       "q3     55.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_ref_v = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "# Check that normalized histograms sum to approx 1\n",
    "assert_valid_prob(human_ref_v)\n",
    "\n",
    "# Check that both files concern the same uncertainty expressions, ordered in the same way\n",
    "assert_same_exprs(human_ref_v, human_ref_v)\n",
    "compute_interquartile_range(human_ref_v, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\\\n",
    "    .drop(\"uncertainty_expression\",axis=1)\\\n",
    "    .mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27ad210f-ef4d-4108-8273-76b909e6fcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncertainty_expression</th>\n",
       "      <th>iqr</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost certain</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>highly likely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very likely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>probable</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somewhat likely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uncertain</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>somewhat unlikely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unlikely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>not likely</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>doubtful</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>very unlikely</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>highly unlikely</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uncertainty_expression   iqr    q1    q3\n",
       "0          almost certain   5.0  90.0  95.0\n",
       "1           highly likely  10.0  85.0  95.0\n",
       "2             very likely  10.0  85.0  95.0\n",
       "3                probable  15.0  65.0  80.0\n",
       "4         somewhat likely  15.0  60.0  75.0\n",
       "5                possible  20.0  55.0  75.0\n",
       "6               uncertain  25.0  25.0  50.0\n",
       "7       somewhat unlikely  15.0  25.0  40.0\n",
       "8                unlikely  10.0  15.0  25.0\n",
       "9              not likely  15.0  10.0  25.0\n",
       "10               doubtful  25.0  10.0  35.0\n",
       "11          very unlikely  10.0   5.0  15.0\n",
       "12        highly unlikely   5.0   5.0  10.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_interquartile_range(human_ref_v, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbfc6c9-7284-4c27-8460-0cf7c7c2ae52",
   "metadata": {},
   "source": [
    "### 2.1. Greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b652f9a-febb-40fc-9735-862b4ea0f0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/greedy/all/verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/sampling__meta-llama__Llama-3-70b-chat-hf_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-0shot/sampling__models__gemini-pro_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/sampling__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/sampling__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/sampling__meta-llama__Llama-3-70b-chat-hf_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/sampling__mistralai__Mixtral-8x22B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/sampling__mistralai__Mixtral-8x7B-Instruct-v0.1_normalized.csv\n",
      "Processing ../../results/greedy/all/verifiable/models-2shot/sampling__models__gemini-pro_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_verifiable_results_iqr_greedy = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/greedy/all/verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_interquartile_range(model_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        # dist[\"setting\"] = \"verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _verifiable_results_iqr_greedy.append(dist)\n",
    "\n",
    "    human_df = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "    dist = compute_interquartile_range(human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "    dist[\"n_shots\"] = n_shots\n",
    "    # dist[\"setting\"] = \"verifiable\"\n",
    "    dist[\"model\"] = \"humans-filtered\"\n",
    "    _verifiable_results_iqr_greedy.append(dist)\n",
    "    \n",
    "_verifiable_results_iqr_greedy = pd.concat(_verifiable_results_iqr_greedy, axis=0).reset_index(drop=True)\n",
    "_verifiable_results_iqr_greedy.loc[\n",
    "    (_verifiable_results_iqr_greedy[\"q1\"] == -1)\n",
    "    & (_verifiable_results_iqr_greedy[\"q3\"] == -1), \"iqr\"\n",
    "] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e4f67-6aa3-41bc-9a68-8db27dc72c13",
   "metadata": {},
   "source": [
    "### 2.2. Probabilistic decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b41c55fa-c461-4d1b-8d51-e7eb7a61c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/probabilistic/all/verifiable/models-0shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-0shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-0shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-0shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-0shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-0shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-0shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-0shot/gpt-4o-2024-05-13_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-2shot/full__allenai__OLMo-7B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-2shot/full__google__gemma-1.1-2b-it_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-2shot/full__lmsys__vicuna-13b-v1.5_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-2shot/full__meta-llama__Meta-Llama-3-8B-Instruct_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-2shot/full__mistralai__Mistral-7B-Instruct-v0.2_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-2shot/gpt-3.5-turbo-0125_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-2shot/gpt-4-turbo-2024-04-09_normalized.csv\n",
      "Processing ../../results/probabilistic/all/verifiable/models-2shot/gpt-4o-2024-05-13_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "_verifiable_results_iqr_prob = []\n",
    "for n_shots in (0, 2):\n",
    "    model_filepaths = sorted(glob.glob(f\"../../results/probabilistic/all/verifiable/models-{n_shots}shot/*_normalized.csv\"))  \n",
    "    for fp in model_filepaths:\n",
    "        print(\"Processing\", fp)\n",
    "        model_df = pd.read_csv(fp, index_col=0)\n",
    "        dist = compute_interquartile_range(model_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "        dist[\"n_shots\"] = n_shots\n",
    "        # dist[\"setting\"] = \"non-verifiable\"\n",
    "        model_name = fp.rpartition(\"shot/\")[-1].rpartition(\"_normalized\")[0]\n",
    "        dist[\"model\"] = model_name\n",
    "        _verifiable_results_iqr_prob.append(dist)\n",
    "\n",
    "    human_df = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "    dist = compute_interquartile_range(human_df, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\n",
    "    dist[\"n_shots\"] = n_shots\n",
    "    # dist[\"setting\"] = \"non-verifiable\"\n",
    "    dist[\"model\"] = \"humans-filtered\"\n",
    "    _verifiable_results_iqr_prob.append(dist)\n",
    "    \n",
    "_verifiable_results_iqr_prob = pd.concat(_verifiable_results_iqr_prob, axis=0).reset_index(drop=True)\n",
    "# If all predictions were -1\n",
    "_verifiable_results_iqr_prob.loc[\n",
    "    (_verifiable_results_iqr_prob[\"q1\"] == -1)\n",
    "    & (_verifiable_results_iqr_prob[\"q3\"] == -1), \"iqr\"\n",
    "] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba7cff-3680-4ac6-adaf-45fac992525d",
   "metadata": {},
   "source": [
    "### 2.3. Final IQR results (verifiable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a10ab42-45c6-4cd5-a319-ac86ef59994b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iqr-greedy</th>\n",
       "      <th>iqr-prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_shots</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">0</th>\n",
       "      <th>full__allenai__OLMo-7B-Instruct</th>\n",
       "      <td>28.461538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__google__gemma-1.1-2b-it</th>\n",
       "      <td>8.461538</td>\n",
       "      <td>18.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__lmsys__vicuna-13b-v1.5</th>\n",
       "      <td>31.923077</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>46.923077</td>\n",
       "      <td>63.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mistralai__Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>45.384615</td>\n",
       "      <td>47.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>83.846154</td>\n",
       "      <td>82.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo-2024-04-09</th>\n",
       "      <td>10.769231</td>\n",
       "      <td>10.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-05-13</th>\n",
       "      <td>11.153846</td>\n",
       "      <td>39.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans-filtered</th>\n",
       "      <td>13.846154</td>\n",
       "      <td>13.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__meta-llama__Llama-3-70b-chat-hf</th>\n",
       "      <td>24.615385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x22B-Instruct-v0.1</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>25.384615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__models__gemini-pro</th>\n",
       "      <td>5.769231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">2</th>\n",
       "      <th>full__allenai__OLMo-7B-Instruct</th>\n",
       "      <td>42.692308</td>\n",
       "      <td>45.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__google__gemma-1.1-2b-it</th>\n",
       "      <td>7.307692</td>\n",
       "      <td>20.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__lmsys__vicuna-13b-v1.5</th>\n",
       "      <td>5.384615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__meta-llama__Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>23.076923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mistralai__Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>48.846154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>31.538462</td>\n",
       "      <td>31.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo-2024-04-09</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>8.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-05-13</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>44.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans-filtered</th>\n",
       "      <td>13.846154</td>\n",
       "      <td>13.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__allenai__OLMo-7B-Instruct</th>\n",
       "      <td>42.692308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__google__gemma-1.1-2b-it</th>\n",
       "      <td>76.923077</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__meta-llama__Llama-3-70b-chat-hf</th>\n",
       "      <td>38.076923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x22B-Instruct-v0.1</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__mistralai__Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>22.692308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling__models__gemini-pro</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          iqr-greedy  \\\n",
       "n_shots model                                                          \n",
       "0       full__allenai__OLMo-7B-Instruct                    28.461538   \n",
       "        full__google__gemma-1.1-2b-it                       8.461538   \n",
       "        full__lmsys__vicuna-13b-v1.5                       31.923077   \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct         46.923077   \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2          45.384615   \n",
       "        gpt-3.5-turbo-0125                                 83.846154   \n",
       "        gpt-4-turbo-2024-04-09                             10.769231   \n",
       "        gpt-4o-2024-05-13                                  11.153846   \n",
       "        humans-filtered                                    13.846154   \n",
       "        sampling__meta-llama__Llama-3-70b-chat-hf          24.615385   \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1   35.000000   \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1    25.384615   \n",
       "        sampling__models__gemini-pro                        5.769231   \n",
       "2       full__allenai__OLMo-7B-Instruct                    42.692308   \n",
       "        full__google__gemma-1.1-2b-it                       7.307692   \n",
       "        full__lmsys__vicuna-13b-v1.5                        5.384615   \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct         23.076923   \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2          48.846154   \n",
       "        gpt-3.5-turbo-0125                                 31.538462   \n",
       "        gpt-4-turbo-2024-04-09                              9.615385   \n",
       "        gpt-4o-2024-05-13                                  10.000000   \n",
       "        humans-filtered                                    13.846154   \n",
       "        sampling__allenai__OLMo-7B-Instruct                42.692308   \n",
       "        sampling__google__gemma-1.1-2b-it                  76.923077   \n",
       "        sampling__meta-llama__Llama-3-70b-chat-hf          38.076923   \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1   20.000000   \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1    22.692308   \n",
       "        sampling__models__gemini-pro                        9.615385   \n",
       "\n",
       "                                                           iqr-prob  \n",
       "n_shots model                                                        \n",
       "0       full__allenai__OLMo-7B-Instruct                         NaN  \n",
       "        full__google__gemma-1.1-2b-it                     18.076923  \n",
       "        full__lmsys__vicuna-13b-v1.5                            NaN  \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct        63.461538  \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2         47.307692  \n",
       "        gpt-3.5-turbo-0125                                82.307692  \n",
       "        gpt-4-turbo-2024-04-09                            10.384615  \n",
       "        gpt-4o-2024-05-13                                 39.384615  \n",
       "        humans-filtered                                   13.846154  \n",
       "        sampling__meta-llama__Llama-3-70b-chat-hf               NaN  \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1        NaN  \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1         NaN  \n",
       "        sampling__models__gemini-pro                            NaN  \n",
       "2       full__allenai__OLMo-7B-Instruct                   45.769231  \n",
       "        full__google__gemma-1.1-2b-it                     20.769231  \n",
       "        full__lmsys__vicuna-13b-v1.5                            NaN  \n",
       "        full__meta-llama__Meta-Llama-3-8B-Instruct              NaN  \n",
       "        full__mistralai__Mistral-7B-Instruct-v0.2               NaN  \n",
       "        gpt-3.5-turbo-0125                                31.230769  \n",
       "        gpt-4-turbo-2024-04-09                             8.846154  \n",
       "        gpt-4o-2024-05-13                                 44.846154  \n",
       "        humans-filtered                                   13.846154  \n",
       "        sampling__allenai__OLMo-7B-Instruct                     NaN  \n",
       "        sampling__google__gemma-1.1-2b-it                       NaN  \n",
       "        sampling__meta-llama__Llama-3-70b-chat-hf               NaN  \n",
       "        sampling__mistralai__Mixtral-8x22B-Instruct-v0.1        NaN  \n",
       "        sampling__mistralai__Mixtral-8x7B-Instruct-v0.1         NaN  \n",
       "        sampling__models__gemini-pro                            NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_iqr_prob_mean = _verifiable_results_iqr_prob[[\"n_shots\", \"model\", \"iqr\"]].groupby([\"n_shots\", \"model\"]).mean()\n",
    "v_iqr_greedy_mean = _verifiable_results_iqr_greedy[[\"n_shots\", \"model\", \"iqr\"]].groupby([\"n_shots\", \"model\"]).mean()\n",
    "v_iqr = v_iqr_greedy_mean.join(v_iqr_prob_mean, lsuffix=\"-greedy\", rsuffix=\"-prob\")\n",
    "v_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "973e5786-c0ef-45e4-9141-499e2870511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      " &  & iqr-greedy & iqr-prob \\\\\n",
      "n_shots & model &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{13}{*}{0} & full__allenai__OLMo-7B-Instruct & 28.46 & NaN \\\\\n",
      " & full__google__gemma-1.1-2b-it & 8.46 & 18.08 \\\\\n",
      " & full__lmsys__vicuna-13b-v1.5 & 31.92 & NaN \\\\\n",
      " & full__meta-llama__Meta-Llama-3-8B-Instruct & 46.92 & 63.46 \\\\\n",
      " & full__mistralai__Mistral-7B-Instruct-v0.2 & 45.38 & 47.31 \\\\\n",
      " & gpt-3.5-turbo-0125 & 83.85 & 82.31 \\\\\n",
      " & gpt-4-turbo-2024-04-09 & 10.77 & 10.38 \\\\\n",
      " & gpt-4o-2024-05-13 & 11.15 & 39.38 \\\\\n",
      " & humans-filtered & 13.85 & 13.85 \\\\\n",
      " & sampling__meta-llama__Llama-3-70b-chat-hf & 24.62 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x22B-Instruct-v0.1 & 35.00 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x7B-Instruct-v0.1 & 25.38 & NaN \\\\\n",
      " & sampling__models__gemini-pro & 5.77 & NaN \\\\\n",
      "\\cline{1-4}\n",
      "\\multirow[t]{15}{*}{2} & full__allenai__OLMo-7B-Instruct & 42.69 & 45.77 \\\\\n",
      " & full__google__gemma-1.1-2b-it & 7.31 & 20.77 \\\\\n",
      " & full__lmsys__vicuna-13b-v1.5 & 5.38 & NaN \\\\\n",
      " & full__meta-llama__Meta-Llama-3-8B-Instruct & 23.08 & NaN \\\\\n",
      " & full__mistralai__Mistral-7B-Instruct-v0.2 & 48.85 & NaN \\\\\n",
      " & gpt-3.5-turbo-0125 & 31.54 & 31.23 \\\\\n",
      " & gpt-4-turbo-2024-04-09 & 9.62 & 8.85 \\\\\n",
      " & gpt-4o-2024-05-13 & 10.00 & 44.85 \\\\\n",
      " & humans-filtered & 13.85 & 13.85 \\\\\n",
      " & sampling__allenai__OLMo-7B-Instruct & 42.69 & NaN \\\\\n",
      " & sampling__google__gemma-1.1-2b-it & 76.92 & NaN \\\\\n",
      " & sampling__meta-llama__Llama-3-70b-chat-hf & 38.08 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x22B-Instruct-v0.1 & 20.00 & NaN \\\\\n",
      " & sampling__mistralai__Mixtral-8x7B-Instruct-v0.1 & 22.69 & NaN \\\\\n",
      " & sampling__models__gemini-pro & 9.62 & NaN \\\\\n",
      "\\cline{1-4}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(v_iqr.to_latex(float_format=\"%.2f\", index=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f86f99-814e-479c-b556-06bca3cdc81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why do we get 0s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000ba0c-4e71-4be7-8733-f143596e8f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b257d7a-9c79-4521-8151-e32027988977",
   "metadata": {},
   "source": [
    "### 1.2. Verifiable (generalization experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabb1e5-8e51-41cb-b18a-f87d1cd40467",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_ref_v = pd.read_csv(\"../../results/greedy/all/verifiable/humans-2shot-filtered/normalized.csv\", index_col=0)\n",
    "# Check that normalized histograms sum to approx 1\n",
    "assert_valid_prob(human_ref_v)\n",
    "\n",
    "# Check that both files concern the same uncertainty expressions, ordered in the same way\n",
    "assert_same_exprs(human_ref_v, human_ref_v)\n",
    "compute_interquartile_range(human_ref_v, uncertainty_expressions=UNCERTAINTY_EXPRESSIONS)\\\n",
    "    .drop(\"uncertainty_expression\",axis=1)\\\n",
    "    .mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
