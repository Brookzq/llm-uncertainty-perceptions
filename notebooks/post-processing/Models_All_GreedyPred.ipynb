{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa7d18b-7611-4c63-8480-b23a61306b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from default_vars import MAPPING_2_CANONIC\n",
    "\n",
    "\n",
    "def map_statement_type(val):\n",
    "    if \"__true_\" in val or val.endswith(\"__true\"): \n",
    "        return \"verifiable__true\"\n",
    "\n",
    "    elif \"__false_\" in val or val.endswith(\"__false\"):\n",
    "        return \"verifiable__false\"\n",
    "    else:\n",
    "        return f\"non-verifiable__{val}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8eaa72-e1f6-4ac7-9cf1-5381cfc7e1ff",
   "metadata": {},
   "source": [
    "In this notebook, we combine all model results into a single canonic form using the argmax prediction as the response.\n",
    "The final CSV file contains the following information:\n",
    "\n",
    "- `model`: the model being evaluated.\n",
    "- `uncertainty_expression`: the uncertainty expression being used to convey uncertainty about the `statement`.\n",
    "- `numerical_response`: the model's predicted argmax numerical response. \n",
    "- `statement_type`: the statement type.\n",
    "- `statement_truth`: the statement truth.\n",
    "- `speaker_name`: the speaker's name.\n",
    "- `speaker_gender`: the speaker's gender.\n",
    "- `template`: the template being used to combine the uncertainty expression, the speaker, and the `statement`.\n",
    "- `statement_id`: the statement id.\n",
    "- `statement`: the statement.\n",
    "- `statement_uuid`: the unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfa18754-e0da-4506-b91b-99a04b6fe75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../results/greedy\"\n",
    "ALL_RESULTS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a6acc-0457-4426-8982-82e819d3ab42",
   "metadata": {},
   "source": [
    "## Approach 1: Top-k (OpenAI models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c510df2d-6c63-4fc2-8c99-4ac04f863c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../results/outputs/non-verifiable-2-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/gpt-4o-2024-05-13/top5_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/gpt-4o-2024-05-13/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/gpt-4o-2024-05-13/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-4o-2024-05-13/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-4o-2024-05-13/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "def map_top_k(df, mapping) -> pd.DataFrame:\n",
    "    can_df = df[mapping.keys()].copy()  \n",
    "    can_df[\"__orig_statement_type\"] = can_df[\"statement_type\"]\n",
    "    can_df[\"statement_type\"] = can_df[\"__orig_statement_type\"].apply(map_statement_type)\n",
    "    can_df = can_df.rename(mapping, axis=1)\n",
    "    return can_df\n",
    "\n",
    "for fp in glob.glob(f\"../../results/outputs/**/top*_completions.csv\", recursive=True):\n",
    "    print(fp)\n",
    "    df = pd.read_csv(fp)\n",
    "    model_name = df.loc[0, \"model\"]\n",
    "    assert model_name in fp\n",
    "    base_name = fp.rpartition(\"results/outputs\")[-1]\\\n",
    "                    .rpartition(\"/\" + model_name)[0]\n",
    "    # ^Note: basename will be non-verifiable-2-shot\n",
    "    # or non-verifiable-0-shot\n",
    "    df = map_top_k(df.copy(), MAPPING_2_CANONIC[\"top-k\"])\n",
    "    df[\"__results_filepath\"] = fp\n",
    "    df[\"__basename\"] = base_name\n",
    "    df[\"__n_shots\"] = 2 if \"2-shot\" in base_name else 0\n",
    "    df[\"__dataset\"] = \"ai2arc\" if \"ai2arc\" in base_name else \"main\"\n",
    "    df[\"__methodology\"] = \"top-k\"\n",
    "\n",
    "    ALL_RESULTS.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84110e53-554d-41ea-bc95-53298cf51f96",
   "metadata": {},
   "source": [
    "### Approach 2: Full Probability (HuggingFace models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6143ea08-eb0c-42b9-a3eb-044bed7e4164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../results/outputs/non-verifiable-2-shot/allenai/OLMo-7B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/google/gemma-1.1-2b-it/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/lmsys/vicuna-13b-v1.5/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/meta-llama/Meta-Llama-3-70B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/meta-llama/Meta-Llama-3-8B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/mistralai/Mistral-7B-Instruct-v0.2/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/allenai/OLMo-7B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/google/gemma-1.1-2b-it/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/lmsys/vicuna-13b-v1.5/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/meta-llama/Meta-Llama-3-70B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/meta-llama/Meta-Llama-3-8B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/mistralai/Mistral-7B-Instruct-v0.2/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/allenai/OLMo-7B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/google/gemma-1.1-2b-it/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/lmsys/vicuna-13b-v1.5/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/meta-llama/Meta-Llama-3-8B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/mistralai/Mistral-7B-Instruct-v0.2/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/allenai/OLMo-7B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/google/gemma-1.1-2b-it/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/lmsys/vicuna-13b-v1.5/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/meta-llama/Meta-Llama-3-8B-Instruct/0_to_100_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/mistralai/Mistral-7B-Instruct-v0.2/0_to_100_completions.csv\n"
     ]
    }
   ],
   "source": [
    "def map_full_prob(df, mapping, id_cols=[\"statement_uuid\", \"statement_type\", \"uncertainty_expression\"]) -> pd.DataFrame:\n",
    "    can_df = df.copy()\n",
    "\n",
    "    # Select argmax\n",
    "    can_df = can_df.sort_values(id_cols + [\"completion__cond_logscores__corrected\"], ascending=False)\n",
    "    can_df = can_df.groupby(id_cols).head(1).reset_index(drop=True)\n",
    "    can_df = can_df[mapping.keys()]\n",
    "    can_df[\"__orig_statement_type\"] = can_df[\"statement_type\"]\n",
    "    can_df[\"statement_type\"] = can_df[\"__orig_statement_type\"].apply(map_statement_type)\n",
    "    can_df = can_df.rename(mapping, axis=1)\n",
    "    return can_df\n",
    "\n",
    "\n",
    "for fp in glob.glob(f\"../../results/outputs/**/0_to_100_completions.csv\", recursive=True):\n",
    "    print(fp)\n",
    "    df = pd.read_csv(fp)\n",
    "    model_name = df.loc[0, \"completion__model\"]\n",
    "    assert model_name in fp\n",
    "    base_name = fp.rpartition(\"results/outputs\")[-1]\\\n",
    "                    .rpartition(\"/\" + model_name)[0]\n",
    "    # ^Note: basename will be non-verifiable-2-shot\n",
    "    # or non-verifiable-0-shot\n",
    "    df = map_full_prob(df.copy(), MAPPING_2_CANONIC[\"full-prob\"])\n",
    "    df[\"__results_filepath\"] = fp\n",
    "    df[\"__basename\"] = base_name\n",
    "    df[\"__n_shots\"] = 2 if \"2-shot\" in base_name else 0\n",
    "    df[\"__dataset\"] = \"ai2arc\" if \"ai2arc\" in base_name else \"main\"\n",
    "    df[\"__methodology\"] = \"full-prob-argmax\"\n",
    "    ALL_RESULTS.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fbf753-f0dd-40e1-96f8-923e2e0d81f0",
   "metadata": {},
   "source": [
    "## Methodology 3: Sampling based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9c43256-6c01-4710-8217-6f2106278174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../results/outputs/non-verifiable-2-shot/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "../../results/outputs/non-verifiable-2-shot/models/gemini-pro/sample_completions.csv\n",
      "../../results/outputs/non-verifiable-0-shot/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "- Skipping...\n",
      "../../results/outputs/non-verifiable-0-shot/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "- Skipping...\n",
      "../../results/outputs/non-verifiable-0-shot/models/gemini-pro/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/allenai/OLMo-7B-Instruct/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/google/gemma-1.1-2b-it/sample_completions.csv\n",
      "- Skipping...\n",
      "../../results/outputs/verifiable-FT-2-shot/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "- Skipping...\n",
      "../../results/outputs/verifiable-FT-2-shot/models/gemini-pro/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/allenai/OLMo-7B-Instruct/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/google/gemma-1.1-2b-it/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "- Skipping...\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/models/gemini-pro/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/allenai/OLMo-7B-Instruct/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/google/gemma-1.1-2b-it/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "- Skipping...\n",
      "../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/models/gemini-pro/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "../../results/outputs/verifiable-FT-0-shot/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "- Skipping...\n",
      "../../results/outputs/verifiable-FT-0-shot/models/gemini-pro/sample_completions.csv\n"
     ]
    }
   ],
   "source": [
    "def map_sampling_based(df, mapping, id_cols=[\"statement_uuid\", \"statement_type\", \"uncertainty_expression\"]) -> pd.DataFrame:\n",
    "    if len(np.unique(df.groupby(id_cols).count().values)) != 1:\n",
    "        return None\n",
    "        \n",
    "    can_df = df.copy()\n",
    "    can_df = can_df[mapping.keys()]\n",
    "    can_df[\"__orig_statement_type\"] = can_df[\"statement_type\"]\n",
    "    can_df[\"statement_type\"] = can_df[\"__orig_statement_type\"].apply(map_statement_type)\n",
    "    can_df = can_df.rename(mapping, axis=1)\n",
    "    return can_df\n",
    "    \n",
    "\n",
    "for fp in glob.glob(f\"../../results/outputs/**/sample_completions.csv\", recursive=True):\n",
    "    print(fp)\n",
    "    df = pd.read_csv(fp)\n",
    "    model_name = df.loc[0, \"model\"]\n",
    "    assert model_name in fp\n",
    "    base_name = fp.rpartition(\"results/outputs\")[-1]\\\n",
    "                    .rpartition(\"/\" + model_name)[0]\n",
    "    # ^Note: basename will be non-verifiable-2-shot\n",
    "    # or non-verifiable-0-shot\n",
    "    df = map_sampling_based(df.copy(), MAPPING_2_CANONIC[\"sampling-based\"])\n",
    "    if df is None:\n",
    "        print(\"- Skipping...\")\n",
    "        continue\n",
    "\n",
    "    df[\"__results_filepath\"] = fp\n",
    "    df[\"__basename\"] = base_name\n",
    "    df[\"__n_shots\"] = 2 if \"2-shot\" in base_name else 0\n",
    "    df[\"__dataset\"] = \"ai2arc\" if \"ai2arc\" in base_name else \"main\"\n",
    "    df[\"__methodology\"] = \"sampling-based\"\n",
    "    ALL_RESULTS.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eb1ce1e-8c1e-4502-939b-6c082439b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCAT_RESULTS = pd.concat(ALL_RESULTS)\n",
    "CONCAT_RESULTS.to_csv(f\"{OUTPUT_DIR}/canonic_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
