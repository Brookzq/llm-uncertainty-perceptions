{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb6b84d-2b06-4944-a270-cea85e7c3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from utils_io import print_sep, read_json, persist_histograms\n",
    "from utils_greedy_histogram import create_histogram_for_top_k_logprobs__openai\n",
    "from default_vars import BIN_CENTER, BIN_OFFSET, UNCERTAINTY_EXPRESSIONS\n",
    "\n",
    "hist_creation_kwargs = dict(\n",
    "    bin_center=BIN_CENTER, \n",
    "    bin_offset=BIN_OFFSET,\n",
    "    uncertainty_expressions=UNCERTAINTY_EXPRESSIONS,\n",
    "    unc_col=\"uncertainty_expression\",\n",
    ")\n",
    "\n",
    "hist_top_k_kwargs = {k: v for k, v in hist_creation_kwargs.items()}\n",
    "hist_top_k_kwargs.update(id_col=\"statement_uuid\", number_col=\"number_1\")\n",
    "\n",
    "\n",
    "def parse_verifiable(df: pd.DataFrame, gen_study=False) -> pd.DataFrame:\n",
    "    assert df[\"statement_type\"].nunique() == (6 if not gen_study else 2), df[\"statement_type\"].unique()\n",
    "    \n",
    "    data = df.copy()\n",
    "    data[\"_statement_type_orig\"] = data[\"statement_type\"]\n",
    "    data[\"statement_type\"] = data[\"_statement_type_orig\"].apply(lambda x: x.split(\"_\")[0].strip())\n",
    "    data[\"statement_truth\"] = data[\"statement_id\"].apply(lambda x: str(\"true\" in x).lower())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d1dff6-65de-4610-b9d0-cae6a84bb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../results\"\n",
    "\n",
    "N_SHOTS = (\n",
    "    0, \n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf09cbb-70b1-4967-9348-c50f32ea27df",
   "metadata": {},
   "source": [
    "# 1. Top-k probabilities \n",
    "\n",
    "In this section, we parse the results obtained via the top-k probability. If the model generates a number among the top-20 log probabilities, then it will be placed in the column `number_1`. Therefore, a greedy histogram can be constructed by assuming this to be most likely number. \n",
    "\n",
    "\n",
    "We've tested 3 different models using this approach, including:\n",
    "- `gpt-3.5-turbo-0125`\n",
    "- `gpt-4-turbo-2024-04-09`\n",
    "- `gpt-4o-2024-05-13`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd5df6-1266-4de3-b074-9d4d5508a54f",
   "metadata": {},
   "source": [
    "## 1.1. Non-verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb4f84e-3a83-4e16-a8e2-a0af57677091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/non-verifiable-0-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/non-verifiable-{n_shot}-shot/**/top*_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = pd.read_csv(fp)\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        assert model_name in fp\n",
    "    \n",
    "        # Overall\n",
    "        histograms = create_histogram_for_top_k_logprobs__openai(df, **hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/non_verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "    \n",
    "        # By gender\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = create_histogram_for_top_k_logprobs__openai(df_gender_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # By statement type\n",
    "        assert 4 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed90d84-c88b-482e-b8aa-ffb11cc51e4a",
   "metadata": {},
   "source": [
    "### 1.2. Verifiable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7cc5175-4b0f-4f88-ba55-80882cb1ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-FT-0-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot/**/top*_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp))\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = create_histogram_for_top_k_logprobs__openai(df, **hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = create_histogram_for_top_k_logprobs__openai(df_gender_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 3 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = create_histogram_for_top_k_logprobs__openai(df_subset_v, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_truth/verifiable/models-{n_shot}shot\", prefix=st_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251d787-21be-4ecb-9daf-f16f73900709",
   "metadata": {},
   "source": [
    "### 1.3. Verifiable (AI2-Arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1458381e-01f0-4816-b542-33f43d31d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "n_shot = 2\n",
    "\n",
    "for ai2arc_subset in (\"ai2arc-easy\", \"ai2arc-challenge\"):\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot-{ai2arc_subset}/**/top*_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp), gen_study=True)\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = create_histogram_for_top_k_logprobs__openai(df, **hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = create_histogram_for_top_k_logprobs__openai(df_gender_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "    \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 1 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "    \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = create_histogram_for_top_k_logprobs__openai(df_subset_v, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_truth/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=st_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd49a9b-9d4e-4fbc-8fdd-1db4e7ef903d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
