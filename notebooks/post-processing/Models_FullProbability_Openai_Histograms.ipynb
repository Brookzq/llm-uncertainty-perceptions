{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb6b84d-2b06-4944-a270-cea85e7c3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import utils_greedy_histogram as greedy_hists\n",
    "import utils_probabilistic_histogram as prob_hists\n",
    "\n",
    "from utils_io import print_sep, read_json, persist_histograms\n",
    "from default_vars import BIN_CENTER, BIN_OFFSET, UNCERTAINTY_EXPRESSIONS\n",
    "\n",
    "full_prob_hist_kwargs = dict(\n",
    "    id_cols=[\"statement_uuid\", \"statement_type\", \"uncertainty_expression\"],\n",
    "    number_col=\"completion__suffix\",\n",
    "    number_logprob_col=\"completion__cond_logscores__corrected\",\n",
    "    unc_col=\"uncertainty_expression\",\n",
    "    uncertainty_expressions=UNCERTAINTY_EXPRESSIONS,\n",
    "    bin_center=BIN_CENTER,\n",
    "    bin_offset=BIN_OFFSET,\n",
    ")\n",
    "\n",
    "\n",
    "def parse_verifiable(df: pd.DataFrame, gen_study=False) -> pd.DataFrame:\n",
    "    assert df[\"statement_type\"].nunique() == (6 if not gen_study else 2), df[\"statement_type\"].unique()\n",
    "    \n",
    "    data = df.copy()\n",
    "    data[\"_statement_type_orig\"] = data[\"statement_type\"]\n",
    "    data[\"statement_type\"] = data[\"_statement_type_orig\"].apply(lambda x: x.split(\"_\")[0].strip())\n",
    "    data[\"statement_truth\"] = data[\"statement_id\"].apply(lambda x: str(\"true\" in x).lower())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d1dff6-65de-4610-b9d0-cae6a84bb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../results\"\n",
    "\n",
    "N_SHOTS = (\n",
    "    0, \n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf09cbb-70b1-4967-9348-c50f32ea27df",
   "metadata": {},
   "source": [
    "# 1. Greedy Histogram\n",
    "\n",
    "In this section, we parse the results obtained via the full probability method. Applicable only to open-source models, we have access to the full probability distribution $p(x | \\text{prompt})$ for $x \\in [0, 100]$. These probabilities are stored in a long-form dataframe, which means that for every example, we have access to 101 rows.\n",
    "Therefore, a greedy histogram can be constructed by obtaining the argmax of every 101 rows. \n",
    "The **full probability** approach concerns the corrected probability of being a number (and no number after). \n",
    "\n",
    "\n",
    "**Algorithms**:\n",
    "---\n",
    "To compute the greedy histograms we proceed as follows: \n",
    "1. Consider the probability distribution over the integer numbers 0, 1, ..., 100 (and no number immediately after).\n",
    "2. Select the argmax prediction of this probability distribution.\n",
    "3. Determine the corresponding bin to the argmax prediction.\n",
    "4. Add 1 to that bin.\n",
    "5. Repeat steps 2-4 for every statement.\n",
    "6. Normalize by the number of statements use.\n",
    "\n",
    "\n",
    "\n",
    "The models which we consider for this analysis are: \n",
    "- `allenai/OLMo-7B-Instruct`\n",
    "- `google/gemma-1.1-2b-it`\n",
    "- `lmsys/vicuna-13b-v1.5`\n",
    "- `meta-llama/Meta-Llama-3-8B-Instruct`\n",
    "- `meta-llama/Meta-Llama-3-70B-Instruct`\n",
    "- `mistralai/Mistral-7B-Instruct-v0.2`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd5df6-1266-4de3-b074-9d4d5508a54f",
   "metadata": {},
   "source": [
    "## 1.1. Non-verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb4f84e-3a83-4e16-a8e2-a0af57677091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/non-verifiable-0-shot/allenai/OLMo-7B-Instruct/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/google/gemma-1.1-2b-it/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/lmsys/vicuna-13b-v1.5/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/meta-llama/Meta-Llama-3-70B-Instruct/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/meta-llama/Meta-Llama-3-8B-Instruct/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/mistralai/Mistral-7B-Instruct-v0.2/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/allenai/OLMo-7B-Instruct/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/google/gemma-1.1-2b-it/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/lmsys/vicuna-13b-v1.5/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/meta-llama/Meta-Llama-3-70B-Instruct/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/meta-llama/Meta-Llama-3-8B-Instruct/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/mistralai/Mistral-7B-Instruct-v0.2/0_to_100_completions.csv\n"
     ]
    }
   ],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    full_prob_filepaths = glob.glob(f\"../../results/outputs/non-verifiable-{n_shot}-shot/**/0_to_100_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in full_prob_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = pd.read_csv(fp)\n",
    "        # ^Note: df size: 101 * n_unique_statements * n_uncertainty expressions\n",
    "        assert (df.groupby([\"uncertainty_expression\", \"statement_uuid\", \"statement_type\"]).count() == 101).all().all()\n",
    "\n",
    "        # Extract name of the model\n",
    "        model_name = df.loc[0, \"completion__model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = \"full__\" + model_name.replace(\"/\", \"__\") \n",
    "    \n",
    "        # Overall\n",
    "        histograms = greedy_hists.create_histogram_for_full_logprobs__hf(df, **full_prob_hist_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/non_verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "    \n",
    "        # By gender\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = greedy_hists.create_histogram_for_full_logprobs__hf(df_gender_subset, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # By statement type\n",
    "        assert 4 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = greedy_hists.create_histogram_for_full_logprobs__hf(df_st_type_subset, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed90d84-c88b-482e-b8aa-ffb11cc51e4a",
   "metadata": {},
   "source": [
    "### 1.2. Verifiable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc5175-4b0f-4f88-ba55-80882cb1ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-FT-0-shot/allenai/OLMo-7B-Instruct/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/google/gemma-1.1-2b-it/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/lmsys/vicuna-13b-v1.5/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/meta-llama/Meta-Llama-3-8B-Instruct/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/mistralai/Mistral-7B-Instruct-v0.2/0_to_100_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/allenai/OLMo-7B-Instruct/0_to_100_completions.csv\n"
     ]
    }
   ],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    full_prob_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot/**/0_to_100_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in full_prob_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp))\n",
    "        # ^Note: df size: 101 * n_unique_statements * n_uncertainty expressions\n",
    "        assert (df.groupby([\"uncertainty_expression\", \"statement_uuid\", \"statement_type\"]).count() == 101).all().all()\n",
    "\n",
    "        # Extract name of the model\n",
    "        model_name = df.loc[0, \"completion__model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = \"full__\" + model_name.replace(\"/\", \"__\") \n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = greedy_hists.create_histogram_for_full_logprobs__hf(df, **full_prob_hist_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = greedy_hists.create_histogram_for_full_logprobs__hf(df_gender_subset, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 3 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = greedy_hists.create_histogram_for_full_logprobs__hf(df_st_type_subset, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = greedy_hists.create_histogram_for_full_logprobs__hf(df_subset_v, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_truth/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251d787-21be-4ecb-9daf-f16f73900709",
   "metadata": {},
   "source": [
    "### 1.3. Verifiable (AI2-Arc)\n",
    "\n",
    "Given the time complexity required to run this strategy. We were not able to include the results for the AI2 ARC in the paper. We leave this for future work. Instead, we used Together AI as the inference server and obtained a greedy continuation. We argue that because these datasets are larger in size (>200) examples than the simpler verifiable and non-verifiable scenarios, we argue that sampling a sequence in a greedy fashion and using those values to compute the greedy histogram, are good reasonable approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86595423-e316-4110-9717-931a54f4d2aa",
   "metadata": {},
   "source": [
    "# Probabilistic Histogram\n",
    "\n",
    "The richer histogram refers to summing the available probability information prediction to create the histogram. \n",
    "That is, regardless of the methodology used (sampling or probability), we accumulate the normalized probability assigned to a number (we assign the remaining probability mass to -1), so that it sums to 1. Whenever a number is not generated, we accumulate a value 1 in the `-1` bin. \n",
    "\n",
    "Whenever computing the probabilistic  top log probability models contain number-specific columns that contain the detailed information about whether a number was present amongst the top-k predicted tokens.\n",
    "\n",
    "**Note**: We do include probability information in the computation of the histogram. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b80d1-850c-4f66-82db-0841eba85632",
   "metadata": {},
   "source": [
    "### 2.1. Non-verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5207178-7c48-437d-8c6b-b0a137025da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    full_prob_filepaths = glob.glob(f\"../../results/outputs/non-verifiable-{n_shot}-shot/**/0_to_100_completions.csv\", recursive=True)\n",
    "\n",
    "    for fp in full_prob_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = pd.read_csv(fp)\n",
    "        # ^Note: df size: 101 * n_unique_statements * n_uncertainty expressions\n",
    "        assert (df.groupby([\"uncertainty_expression\", \"statement_uuid\", \"statement_type\"]).count() == 101).all().all()\n",
    "\n",
    "        # Extract name of the model\n",
    "        model_name = df.loc[0, \"completion__model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = \"full__\" + model_name.replace(\"/\", \"__\") \n",
    "\n",
    "        # Overall\n",
    "        histograms = prob_hists.create_histogram_for_full_logprobs__hf(df, **full_prob_hist_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/all/non_verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "    \n",
    "        # By gender\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = prob_hists.create_histogram_for_full_logprobs__hf(df_gender_subset, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_gender/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # By statement type\n",
    "        assert 4 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = prob_hists.create_histogram_for_full_logprobs__hf(df_st_type_subset, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_statement_type/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b02c8-62e1-4d68-8ffb-4db5bbaf286a",
   "metadata": {},
   "source": [
    "### 2.2. Verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938bf1d-05a7-4b06-a96d-8e50f2e2acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    full_prob_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot/**/0_to_100_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in full_prob_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp))\n",
    "        # ^Note: df size: 101 * n_unique_statements * n_uncertainty expressions\n",
    "        assert (df.groupby([\"uncertainty_expression\", \"statement_uuid\", \"statement_type\"]).count() == 101).all().all()\n",
    "\n",
    "        # Extract name of the model\n",
    "        model_name = df.loc[0, \"completion__model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = \"full__\" + model_name.replace(\"/\", \"__\") \n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = prob_hists.create_histogram_for_full_logprobs__hf(df, **full_prob_hist_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/all/verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = prob_hists.create_histogram_for_full_logprobs__hf(df_gender_subset, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_gender/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 3 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = prob_hists.create_histogram_for_full_logprobs__hf(df_st_type_subset, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_statement_type/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = prob_hists.create_histogram_for_full_logprobs__hf(df_subset_v, **full_prob_hist_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_statement_truth/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38787d-5c1f-41ba-a639-fb87f4d11904",
   "metadata": {},
   "source": [
    "### 2.3. Verifiable (AI2-Arc)\n",
    "\n",
    "Given the time complexity required to run this strategy. We were not able to include the results for the AI2 ARC in the paper. We leave this for future work. Instead, we used greedy decoding to obtain a response from the same models. \n",
    "Please consider running the notebook `Models_Sampled_Completions_Histograms` instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
