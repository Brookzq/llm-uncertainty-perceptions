{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb6b84d-2b06-4944-a270-cea85e7c3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import utils_greedy_histogram as greedy_hists\n",
    "import utils_probabilistic_histogram as prob_hists\n",
    "\n",
    "from utils_io import print_sep, read_json, persist_histograms\n",
    "from default_vars import BIN_CENTER, BIN_OFFSET, UNCERTAINTY_EXPRESSIONS\n",
    "\n",
    "def parse_verifiable(df: pd.DataFrame, gen_study=False) -> pd.DataFrame:\n",
    "    assert df[\"statement_type\"].nunique() == (6 if not gen_study else 2), df[\"statement_type\"].unique()\n",
    "    \n",
    "    data = df.copy()\n",
    "    data[\"_statement_type_orig\"] = data[\"statement_type\"]\n",
    "    data[\"statement_type\"] = data[\"_statement_type_orig\"].apply(lambda x: x.split(\"_\")[0].strip())\n",
    "    data[\"statement_truth\"] = data[\"statement_id\"].apply(lambda x: str(\"true\" in x).lower())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d1dff6-65de-4610-b9d0-cae6a84bb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../results\"\n",
    "\n",
    "N_SHOTS = (\n",
    "    0, \n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf09cbb-70b1-4967-9348-c50f32ea27df",
   "metadata": {},
   "source": [
    "# 1. Greedy Histogram\n",
    "\n",
    "In this section, we parse the results obtained via the sampling based approach. \n",
    "In general, we generate `k` samples from the same prompt and collect the majority vote across the generations. \n",
    "\n",
    "If the model generates a number among the top-20 log probabilities, then it will be placed in the column `number_1`. Therefore, a greedy histogram can be constructed by assuming this to be most likely number. \n",
    "\n",
    "In the general case, we compute the histogram by following the steps: \n",
    "1. Compute the empirical frequency of each number.\n",
    "2. Pick the continuation that maximizes the empirical frequency (i.e., majority vote)\n",
    "3. Determine its bin.\n",
    "4. Add to the current count of that bin.\n",
    "5. Repeat steps 1-4 for every statement.\n",
    "6. Finally, normalize by the number of unique statements.\n",
    "\n",
    "\n",
    "In this study, we use the sample-based algorithm with greedy decoding (`n=1`) for the following models:\n",
    "- `Meta/Llama-3-70b-chat-hf`, run using TogetherAI for efficiency purposes.\n",
    "- `mistralai/Mixtral-8x7B-Instruct-v0.1`\n",
    "- `mistralai/Mixtral-8x22B-Instruct-v0.1`\n",
    "- `gemini-pro`\n",
    "\n",
    "**Note**: Heuristically, we define the first number as being the accurate response. \n",
    "This naturally warrants more investigation, to assess the validity of this heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4899f0eb-cc25-4181-9ae6-a1070c4f5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_sampl_kwargs = dict(\n",
    "    id_cols=[\"statement_uuid\", \"statement_type\", \"uncertainty_expression\"],\n",
    "    number_col=\"response_first_number\",\n",
    "    unc_col=\"uncertainty_expression\",\n",
    "    uncertainty_expressions=UNCERTAINTY_EXPRESSIONS,\n",
    "    bin_center=BIN_CENTER,\n",
    "    bin_offset=BIN_OFFSET,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd5df6-1266-4de3-b074-9d4d5508a54f",
   "metadata": {},
   "source": [
    "## 1.1. Non-verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb4f84e-3a83-4e16-a8e2-a0af57677091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/non-verifiable-0-shot/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n"
     ]
    }
   ],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    sample_filepaths = glob.glob(f\"../../results/outputs/non-verifiable-{n_shot}-shot/**/sample_completions.csv\", recursive=True)\n",
    "\n",
    "    for fp in sample_filepaths:\n",
    "        if \"gemini\" in fp:\n",
    "            continue\n",
    "        print(\"Processing\", fp); \n",
    "        df = pd.read_csv(fp)\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        prefix = \"sampling__\" + model_name.replace(\"/\", \"__\")\n",
    "        assert model_name in fp\n",
    "    \n",
    "        # Overall\n",
    "        histograms = greedy_hists.create_histogram_for_sampling_approach(df, **hist_sampl_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/non_verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "    \n",
    "        # By gender\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = greedy_hists.create_histogram_for_sampling_approach(df_gender_subset, **hist_sampl_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # By statement type\n",
    "        assert 4 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = greedy_hists.create_histogram_for_sampling_approach(df_st_type_subset, **hist_sampl_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed90d84-c88b-482e-b8aa-ffb11cc51e4a",
   "metadata": {},
   "source": [
    "### 1.2. Verifiable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cc5175-4b0f-4f88-ba55-80882cb1ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-FT-0-shot/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/models/gemini-pro/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/allenai/OLMo-7B-Instruct/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/google/gemma-1.1-2b-it/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/models/gemini-pro/sample_completions.csv\n"
     ]
    }
   ],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    sample_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot/**/sample_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in sample_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp))\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = \"sampling__\" + model_name.replace(\"/\", \"__\")\n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = greedy_hists.create_histogram_for_sampling_approach(df, **hist_sampl_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = greedy_hists.create_histogram_for_sampling_approach(df_gender_subset, **hist_sampl_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 3 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = greedy_hists.create_histogram_for_sampling_approach(df_st_type_subset, **hist_sampl_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = greedy_hists.create_histogram_for_sampling_approach(df_subset_v, **hist_sampl_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_truth/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251d787-21be-4ecb-9daf-f16f73900709",
   "metadata": {},
   "source": [
    "### 1.3. Verifiable (AI2-Arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1458381e-01f0-4816-b542-33f43d31d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/allenai/OLMo-7B-Instruct/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/google/gemma-1.1-2b-it/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/models/gemini-pro/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/allenai/OLMo-7B-Instruct/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/google/gemma-1.1-2b-it/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/meta-llama/Llama-3-70b-chat-hf/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/mistralai/Mixtral-8x22B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/mistralai/Mixtral-8x7B-Instruct-v0.1/sample_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/models/gemini-pro/sample_completions.csv\n"
     ]
    }
   ],
   "source": [
    "n_shot = 2\n",
    "\n",
    "for ai2arc_subset in (\"ai2arc-easy\", \"ai2arc-challenge\"):\n",
    "    sample_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot-{ai2arc_subset}/**/sample_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in sample_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp), gen_study=True)\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = \"sampling__\" + model_name.replace(\"/\", \"__\")\n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = greedy_hists.create_histogram_for_sampling_approach(df, **hist_sampl_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = greedy_hists.create_histogram_for_sampling_approach(df_gender_subset, **hist_sampl_kwargs, ok_non_symmetric=True)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "    \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 1 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = greedy_hists.create_histogram_for_sampling_approach(df_st_type_subset, **hist_sampl_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "    \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = greedy_hists.create_histogram_for_sampling_approach(df_subset_v, **hist_sampl_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_truth/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+st_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b6286-e5c6-4603-909c-0cf0ab690462",
   "metadata": {},
   "source": [
    "Because of budget constraints, we could not run this method using multiple samples (i.e., k>>1). Instead, we only run the sampling methodology using `k=1` and greedy decoding. For that reason, if we were to compute the probabilistic histogram vs the greedy histogram the two histograms would be the same. Future work should consider running the same experiment using multiple samples and determine whether significative differences exist between greedy decoding and sampling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
