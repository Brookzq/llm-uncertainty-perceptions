{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb6b84d-2b06-4944-a270-cea85e7c3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import utils_greedy_histogram as greedy_hists\n",
    "import utils_probabilistic_histogram as prob_hists\n",
    "\n",
    "from utils_io import print_sep, read_json, persist_histograms\n",
    "from default_vars import BIN_CENTER, BIN_OFFSET, UNCERTAINTY_EXPRESSIONS\n",
    "\n",
    "hist_creation_kwargs = dict(\n",
    "    bin_center=BIN_CENTER, \n",
    "    bin_offset=BIN_OFFSET,\n",
    "    uncertainty_expressions=UNCERTAINTY_EXPRESSIONS,\n",
    "    unc_col=\"uncertainty_expression\",\n",
    ")\n",
    "\n",
    "hist_top_k_kwargs = {k: v for k, v in hist_creation_kwargs.items()}\n",
    "hist_top_k_kwargs.update(id_col=\"statement_uuid\", number_col=\"number_1\")\n",
    "\n",
    "def parse_verifiable(df: pd.DataFrame, gen_study=False) -> pd.DataFrame:\n",
    "    assert df[\"statement_type\"].nunique() == (6 if not gen_study else 2), df[\"statement_type\"].unique()\n",
    "    \n",
    "    data = df.copy()\n",
    "    data[\"_statement_type_orig\"] = data[\"statement_type\"]\n",
    "    data[\"statement_type\"] = data[\"_statement_type_orig\"].apply(lambda x: x.split(\"_\")[0].strip())\n",
    "    data[\"statement_truth\"] = data[\"statement_id\"].apply(lambda x: str(\"true\" in x).lower())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d1dff6-65de-4610-b9d0-cae6a84bb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../results\"\n",
    "\n",
    "N_SHOTS = (\n",
    "    0, \n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf09cbb-70b1-4967-9348-c50f32ea27df",
   "metadata": {},
   "source": [
    "# 1. Greedy Histogram\n",
    "\n",
    "In this section, we parse the results obtained via the top-k probability. If the model generates a number among the top-20 log probabilities, then it will be placed in the column `number_1`. Therefore, a greedy histogram can be constructed by assuming this to be most likely number. \n",
    "\n",
    "\n",
    "We've tested 3 different models using this approach, including:\n",
    "- `gpt-3.5-turbo-0125`\n",
    "- `gpt-4-turbo-2024-04-09`\n",
    "- `gpt-4o-2024-05-13`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd5df6-1266-4de3-b074-9d4d5508a54f",
   "metadata": {},
   "source": [
    "## 1.1. Non-verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb4f84e-3a83-4e16-a8e2-a0af57677091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/non-verifiable-0-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-0-shot/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/non-verifiable-2-shot/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/non-verifiable-{n_shot}-shot/**/top*_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = pd.read_csv(fp)\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        assert model_name in fp\n",
    "    \n",
    "        # Overall\n",
    "        histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df, **hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/non_verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "    \n",
    "        # By gender\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df_gender_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # By statement type\n",
    "        assert 4 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed90d84-c88b-482e-b8aa-ffb11cc51e4a",
   "metadata": {},
   "source": [
    "### 1.2. Verifiable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7cc5175-4b0f-4f88-ba55-80882cb1ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-FT-0-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-0-shot/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot/**/top*_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp))\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df, **hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df_gender_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 3 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df_subset_v, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_truth/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251d787-21be-4ecb-9daf-f16f73900709",
   "metadata": {},
   "source": [
    "### 1.3. Verifiable (AI2-Arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1458381e-01f0-4816-b542-33f43d31d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-easy/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-FT-2-shot-ai2arc-challenge/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "n_shot = 2\n",
    "\n",
    "for ai2arc_subset in (\"ai2arc-easy\", \"ai2arc-challenge\"):\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot-{ai2arc_subset}/**/top*_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp), gen_study=True)\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df, **hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/all/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df_gender_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_gender/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "    \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 1 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_type/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "    \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df_subset_v, **hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/by_statement_truth/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+st_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c216d6a-2590-4277-a2f1-00d0a9610874",
   "metadata": {},
   "source": [
    "### 1.4. Ablation of exemplars\n",
    "\n",
    "When determining the configuration of the exemplars to use in the verifiable 2-shot experiments, we ran some preliminary experiments using gpt-3.5, gpt-4o, and gpt-4 to quantify the impact that these would have in the final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900376e4-fac1-4b27-96c8-818d7511eefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FF/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FF/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FF/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FT/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FT/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FT/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TF/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TF/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TF/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TT/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TT/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TT/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "top_k_filepaths = glob.glob(f\"../../results/outputs/verifiable-2-shot-exemplars-ablation/**/top*_completions.csv\", recursive=True)\n",
    "\n",
    "for fp in top_k_filepaths:\n",
    "    print(\"Processing\", fp); \n",
    "    df = parse_verifiable(pd.read_csv(fp))\n",
    "    model_name = df.loc[0, \"model\"]\n",
    "    assert model_name in fp\n",
    "    prefix = model_name.replace(\"/\", \"__\")\n",
    "\n",
    "    config = fp.rpartition(\"results-2shot-\")[-1][:2]\n",
    "    # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "    # Overall\n",
    "    # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "    histograms = greedy_hists.create_histogram_for_top_k_logprobs__openai(df, **hist_top_k_kwargs)\n",
    "    persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/greedy/verifiable-2-shot-exemplars-ablation/all/models-2shot-{config}\", prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86595423-e316-4110-9717-931a54f4d2aa",
   "metadata": {},
   "source": [
    "# Probabilistic Histogram\n",
    "\n",
    "The richer histogram refers to summing the available probability information prediction to create the histogram. \n",
    "That is, regardless of the methodology used (sampling or probability), we accumulate the normalized probability assigned to a number (we assign the remaining probability mass to -1), so that it sums to 1. Whenever a number is not generated, we accumulate a value 1 in the `-1` bin. \n",
    "\n",
    "Whenever computing the probabilistic  top log probability models contain number-specific columns that contain the detailed information about whether a number was present amongst the top-k predicted tokens.\n",
    "\n",
    "**Algorithm**: \n",
    "---\n",
    "To compute the probabilistic histogram for *top-k* approaches where we have partial information about the probabilities, we will:\n",
    "1. pick the all numbers among top-k and sum their probability mass.\n",
    "2. determine the remainder 1- total_prob_mass_in_top_k is assigned to bin -1\n",
    "3. determine their bin, \n",
    "4. sum the probabilities to the current count of that bin.\n",
    "5. repeat steps 1 through 3 for every statement.\n",
    "6. Finally, we normalize by the number of statements used.\n",
    "\n",
    "\n",
    "**Note**: We do include probability information in the computation of the histogram. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d29c43b2-55bc-4061-b9fd-46e81c71b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic histogram keyword arguments\n",
    "prob_hist_top_k_kwargs = {k: v for k, v in hist_creation_kwargs.items()}\n",
    "prob_hist_top_k_kwargs.update(\n",
    "    id_col=\"statement_uuid\",\n",
    "    number_cols=[f\"number_{i}\" for i in range(1, 20)], \n",
    "    number_logprob_cols=[f\"number_{i}_logprob\" for i in range(1, 20)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b80d1-850c-4f66-82db-0841eba85632",
   "metadata": {},
   "source": [
    "### 2.1. Non-verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5207178-7c48-437d-8c6b-b0a137025da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/non-verifiable-{n_shot}-shot/**/top*_completions.csv\", recursive=True)\n",
    "\n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = pd.read_csv(fp)\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        assert model_name in fp\n",
    "    \n",
    "        # Overall\n",
    "        histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df, **prob_hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/all/non_verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "    \n",
    "        # By gender\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df_gender_subset, **prob_hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_gender/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # By statement type\n",
    "        assert 4 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **prob_hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_statement_type/non_verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b02c8-62e1-4d68-8ffb-4db5bbaf286a",
   "metadata": {},
   "source": [
    "### 2.2. Verifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938bf1d-05a7-4b06-a96d-8e50f2e2acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_shot in N_SHOTS:\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot/**/top*_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp))\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df, **prob_hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/all/verifiable/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df_gender_subset, **prob_hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_gender/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 3 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **prob_hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_statement_type/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df_subset_v, **prob_hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_statement_truth/verifiable/models-{n_shot}shot\", prefix=prefix+\"_\"+st_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38787d-5c1f-41ba-a639-fb87f4d11904",
   "metadata": {},
   "source": [
    "### 2.3. Verifiable (AI2-Arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5da2f6-9ded-48f3-9aef-b7df73c91887",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shot = 2\n",
    "\n",
    "for ai2arc_subset in (\"ai2arc-easy\", \"ai2arc-challenge\"):\n",
    "    top_k_filepaths = glob.glob(f\"../../results/outputs/verifiable-FT-{n_shot}-shot-{ai2arc_subset}/**/top*_completions.csv\", recursive=True)\n",
    "    \n",
    "    for fp in top_k_filepaths:\n",
    "        print(\"Processing\", fp); \n",
    "        df = parse_verifiable(pd.read_csv(fp), gen_study=True)\n",
    "        model_name = df.loc[0, \"model\"]\n",
    "        assert model_name in fp\n",
    "        prefix = model_name.replace(\"/\", \"__\")\n",
    "        \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Overall\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df, **prob_hist_top_k_kwargs)\n",
    "        persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/all/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix)\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Gender\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        for gender in (\"male\", \"female\"):\n",
    "            df_gender_subset = df[df[\"gender\"] == gender].copy()\n",
    "            assert len(df_gender_subset) < len(df)\n",
    "            histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df_gender_subset, **prob_hist_top_k_kwargs, ok_non_symmetric=True)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_gender/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+gender)\n",
    "    \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement type\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 1 == df[\"statement_type\"].nunique()\n",
    "        for st_type in df[\"statement_type\"].unique():\n",
    "            df_st_type_subset = df[df[\"statement_type\"] == st_type].copy()\n",
    "            assert df_st_type_subset[\"statement_type\"].nunique() == 1\n",
    "            histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df_st_type_subset, **prob_hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_statement_type/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+st_type)\n",
    "    \n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        # Statement truth/falsity\n",
    "        # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "        assert 2 == df[\"statement_truth\"].nunique()\n",
    "        for st_truth in df[\"statement_truth\"].unique():\n",
    "            df_subset_v = df[df[\"statement_truth\"] == st_truth]\n",
    "            assert len(df_subset_v) < len(df)    \n",
    "            histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df_subset_v, **prob_hist_top_k_kwargs)\n",
    "            persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/by_statement_truth/verifiable-{ai2arc_subset}/models-{n_shot}shot\", prefix=prefix+\"_\"+st_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467881c2-2589-4ac9-bdf3-30ebcd23b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In the cell above, you will see that we set \n",
    "# ok_non_symmetric=True, when dealing with gender.\n",
    "# This is related to the fact that we had more statements\n",
    "# than gendered names and therefore, we randomly sampled\n",
    "# the name assignment. As a result, this led to a slight\n",
    "# non-symmetrical balancing of the examples. See example\n",
    "# below for a better understanding\n",
    "df_gender_subset1 = df[df[\"gender\"] == \"female\"].copy()\n",
    "df_gender_subset1.groupby(\"uncertainty_expression\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88788f24-703b-45fd-af12-60c868e7be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender_subset2 = df[df[\"gender\"] == \"male\"].copy()\n",
    "df_gender_subset2.groupby(\"uncertainty_expression\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb919d-9eb3-47f2-8f88-8cd8069bc598",
   "metadata": {},
   "source": [
    "### Probabilistic decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9109047e-d999-43e0-a01c-fff29bb71504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FF/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FF/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FF/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FT/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FT/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-FT/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TF/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TF/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TF/gpt-4o-2024-05-13/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TT/gpt-3.5-turbo-0125/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TT/gpt-4-turbo-2024-04-09/top5_completions.csv\n",
      "Processing ../../results/outputs/verifiable-2-shot-exemplars-ablation/results-2shot-TT/gpt-4o-2024-05-13/top5_completions.csv\n"
     ]
    }
   ],
   "source": [
    "top_k_filepaths = glob.glob(f\"../../results/outputs/verifiable-2-shot-exemplars-ablation/**/top*_completions.csv\", recursive=True)\n",
    "\n",
    "for fp in top_k_filepaths:\n",
    "    print(\"Processing\", fp); \n",
    "    df = parse_verifiable(pd.read_csv(fp))\n",
    "    model_name = df.loc[0, \"model\"]\n",
    "    assert model_name in fp\n",
    "    prefix = model_name.replace(\"/\", \"__\")\n",
    "\n",
    "    config = fp.rpartition(\"results-2shot-\")[-1][:2]\n",
    "    # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "    # Overall\n",
    "    # ---- ---- ---- ---- ---- ---- ---- ----\n",
    "    histograms = prob_hists.create_histogram_for_top_k_logprobs__openai(df, **prob_hist_top_k_kwargs)\n",
    "    persist_histograms(*histograms, results_folder=f\"{OUTPUT_DIR}/probabilistic/verifiable-2-shot-exemplars-ablation/all/models-2shot-{config}\", prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ddb6f-85fe-4763-85aa-38ce988090ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
